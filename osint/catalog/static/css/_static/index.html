

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta property="og:title" content="Transformers" />
  <meta property="og:type" content="website" />
  <meta property="og:url" content="index.html" />
  <meta property="og:description" content="State-of-the-art Natural Language Processing for Jax, Pytorch and TensorFlow 🤗 Transformers (formerly known as pytorch-transformers and pytorch-pretrained-be..." />
  <meta property="og:image" content="https://huggingface.co/front/thumbnails/transformers.png" />
  <meta property="og:image:alt" content="Transformers" />
  <meta name="twitter:image" content="https://huggingface.co/front/thumbnails/transformers.png">
<meta name="twitter:description" content="State-of-the-art Natural Language Processing for PyTorch and TensorFlow 2.0. Transformers provides thousands of pretrained models to perform tasks on texts such as classification, information extraction, question answering, summarization, translation, text generation, etc in 100+ languages. Its aim is to make cutting-edge NLP easier to use for everyone">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Transformers &mdash; transformers 4.5.0.dev0 documentation</title>
  

  
  
    <link rel="shortcut icon" href="_static/favicon.ico"/>
  
  
  

  
  <script type="text/javascript" src="_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script src="_static/language_data.js"></script>
        <script src="_static/clipboard.min.js"></script>
        <script src="_static/copybutton.js"></script>
        <script src="_static/js/custom.js"></script>
        <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="_static/copybutton.css" type="text/css" />
  <link rel="stylesheet" href="_static/css/huggingface.css" type="text/css" />
  <link rel="stylesheet" href="_static/css/code-snippets.css" type="text/css" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Quick tour" href="quicktour.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="#" class="icon icon-home"> transformers
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Get started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="quicktour.html">Quick tour</a></li>
<li class="toctree-l1"><a class="reference internal" href="installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="philosophy.html">Philosophy</a></li>
<li class="toctree-l1"><a class="reference internal" href="glossary.html">Glossary</a></li>
</ul>
<p class="caption"><span class="caption-text">Using 🤗 Transformers</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="task_summary.html">Summary of the tasks</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_summary.html">Summary of the models</a></li>
<li class="toctree-l1"><a class="reference internal" href="preprocessing.html">Preprocessing data</a></li>
<li class="toctree-l1"><a class="reference internal" href="training.html">Fine-tuning a pretrained model</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_sharing.html">Model sharing and uploading</a></li>
<li class="toctree-l1"><a class="reference internal" href="tokenizer_summary.html">Summary of the tokenizers</a></li>
<li class="toctree-l1"><a class="reference internal" href="multilingual.html">Multi-lingual models</a></li>
</ul>
<p class="caption"><span class="caption-text">Advanced guides</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="pretrained_models.html">Pretrained models</a></li>
<li class="toctree-l1"><a class="reference internal" href="examples.html">Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="troubleshooting.html">Troubleshooting</a></li>
<li class="toctree-l1"><a class="reference internal" href="custom_datasets.html">Fine-tuning with custom datasets</a></li>
<li class="toctree-l1"><a class="reference internal" href="notebooks.html">🤗 Transformers Notebooks</a></li>
<li class="toctree-l1"><a class="reference internal" href="sagemaker.html">Run training on Amazon SageMaker</a></li>
<li class="toctree-l1"><a class="reference internal" href="community.html">Community</a></li>
<li class="toctree-l1"><a class="reference internal" href="converting_tensorflow_models.html">Converting Tensorflow Checkpoints</a></li>
<li class="toctree-l1"><a class="reference internal" href="migration.html">Migrating from previous packages</a></li>
<li class="toctree-l1"><a class="reference internal" href="contributing.html">How to contribute to transformers?</a></li>
<li class="toctree-l1"><a class="reference internal" href="add_new_model.html">How to add a model to 🤗 Transformers?</a></li>
<li class="toctree-l1"><a class="reference internal" href="fast_tokenizers.html">Using tokenizers from 🤗 Tokenizers</a></li>
<li class="toctree-l1"><a class="reference internal" href="testing.html">Testing</a></li>
<li class="toctree-l1"><a class="reference internal" href="debugging.html">Debugging</a></li>
<li class="toctree-l1"><a class="reference internal" href="serialization.html">Exporting transformers models</a></li>
</ul>
<p class="caption"><span class="caption-text">Research</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="bertology.html">BERTology</a></li>
<li class="toctree-l1"><a class="reference internal" href="perplexity.html">Perplexity of fixed-length models</a></li>
<li class="toctree-l1"><a class="reference internal" href="benchmarks.html">Benchmarks</a></li>
</ul>
<p class="caption"><span class="caption-text">Main Classes</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="main_classes/callback.html">Callbacks</a></li>
<li class="toctree-l1"><a class="reference internal" href="main_classes/configuration.html">Configuration</a></li>
<li class="toctree-l1"><a class="reference internal" href="main_classes/data_collator.html">Data Collator</a></li>
<li class="toctree-l1"><a class="reference internal" href="main_classes/logging.html">Logging</a></li>
<li class="toctree-l1"><a class="reference internal" href="main_classes/model.html">Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="main_classes/optimizer_schedules.html">Optimization</a></li>
<li class="toctree-l1"><a class="reference internal" href="main_classes/output.html">Model outputs</a></li>
<li class="toctree-l1"><a class="reference internal" href="main_classes/pipelines.html">Pipelines</a></li>
<li class="toctree-l1"><a class="reference internal" href="main_classes/processors.html">Processors</a></li>
<li class="toctree-l1"><a class="reference internal" href="main_classes/tokenizer.html">Tokenizer</a></li>
<li class="toctree-l1"><a class="reference internal" href="main_classes/trainer.html">Trainer</a></li>
<li class="toctree-l1"><a class="reference internal" href="main_classes/feature_extractor.html">Feature Extractor</a></li>
</ul>
<p class="caption"><span class="caption-text">Models</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="model_doc/albert.html">ALBERT</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/auto.html">Auto Classes</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/bart.html">BART</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/barthez.html">BARThez</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/bert.html">BERT</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/bertweet.html">Bertweet</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/bertgeneration.html">BertGeneration</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/bert_japanese.html">BertJapanese</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/bigbird.html">BigBird</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/bigbird_pegasus.html">BigBirdPegasus</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/blenderbot.html">Blenderbot</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/blenderbot_small.html">Blenderbot Small</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/bort.html">BORT</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/camembert.html">CamemBERT</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/clip.html">CLIP</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/convbert.html">ConvBERT</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/cpm.html">CPM</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/ctrl.html">CTRL</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/deberta.html">DeBERTa</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/deberta_v2.html">DeBERTa-v2</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/deit.html">DeiT</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/dialogpt.html">DialoGPT</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/distilbert.html">DistilBERT</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/dpr.html">DPR</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/electra.html">ELECTRA</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/encoderdecoder.html">Encoder Decoder Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/flaubert.html">FlauBERT</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/fsmt.html">FSMT</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/funnel.html">Funnel Transformer</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/herbert.html">herBERT</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/ibert.html">I-BERT</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/layoutlm.html">LayoutLM</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/led.html">LED</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/longformer.html">Longformer</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/luke.html">LUKE</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/lxmert.html">LXMERT</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/marian.html">MarianMT</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/m2m_100.html">M2M100</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/mbart.html">MBart and MBart-50</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/megatron_bert.html">MegatronBERT</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/megatron_gpt2.html">MegatronGPT2</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/mobilebert.html">MobileBERT</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/mpnet.html">MPNet</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/mt5.html">MT5</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/gpt.html">OpenAI GPT</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/gpt2.html">OpenAI GPT2</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/gpt_neo.html">GPT Neo</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/pegasus.html">Pegasus</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/phobert.html">PhoBERT</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/prophetnet.html">ProphetNet</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/rag.html">RAG</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/reformer.html">Reformer</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/retribert.html">RetriBERT</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/roberta.html">RoBERTa</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/speech_to_text.html">Speech2Text</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/squeezebert.html">SqueezeBERT</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/t5.html">T5</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/tapas.html">TAPAS</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/transformerxl.html">Transformer XL</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/vit.html">Vision Transformer (ViT)</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/wav2vec2.html">Wav2Vec2</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/xlm.html">XLM</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/xlmprophetnet.html">XLM-ProphetNet</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/xlmroberta.html">XLM-RoBERTa</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/xlnet.html">XLNet</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/xlsr_wav2vec2.html">XLSR-Wav2Vec2</a></li>
</ul>
<p class="caption"><span class="caption-text">Internal Helpers</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="internal/modeling_utils.html">Custom Layers and Utilities</a></li>
<li class="toctree-l1"><a class="reference internal" href="internal/pipelines_utils.html">Utilities for pipelines</a></li>
<li class="toctree-l1"><a class="reference internal" href="internal/tokenization_utils.html">Utilities for Tokenizers</a></li>
<li class="toctree-l1"><a class="reference internal" href="internal/trainer_utils.html">Utilities for Trainer</a></li>
<li class="toctree-l1"><a class="reference internal" href="internal/generation_utils.html">Utilities for Generation</a></li>
<li class="toctree-l1"><a class="reference internal" href="internal/file_utils.html">General Utilities</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="#">transformers</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="#">Docs</a> &raquo;</li>
        
      <li>Transformers</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/index.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="transformers">
<h1>Transformers<a class="headerlink" href="#transformers" title="Permalink to this headline">¶</a></h1>
<p>State-of-the-art Natural Language Processing for Jax, Pytorch and TensorFlow</p>
<p>🤗 Transformers (formerly known as <cite>pytorch-transformers</cite> and <cite>pytorch-pretrained-bert</cite>) provides general-purpose
architectures (BERT, GPT-2, RoBERTa, XLM, DistilBert, XLNet…) for Natural Language Understanding (NLU) and Natural
Language Generation (NLG) with over 32+ pretrained models in 100+ languages and deep interoperability between Jax,
PyTorch and TensorFlow.</p>
<p>This is the documentation of our repository <a class="reference external" href="https://github.com/huggingface/transformers">transformers</a>.</p>
<div class="section" id="features">
<h2>Features<a class="headerlink" href="#features" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>High performance on NLU and NLG tasks</p></li>
<li><p>Low barrier to entry for educators and practitioners</p></li>
</ul>
<p>State-of-the-art NLP for everyone:</p>
<ul class="simple">
<li><p>Deep learning researchers</p></li>
<li><p>Hands-on practitioners</p></li>
<li><p>AI/ML/NLP teachers and educators</p></li>
</ul>
<p>Lower compute costs, smaller carbon footprint:</p>
<ul class="simple">
<li><p>Researchers can share trained models instead of always retraining</p></li>
<li><p>Practitioners can reduce compute time and production costs</p></li>
<li><p>8 architectures with over 30 pretrained models, some in more than 100 languages</p></li>
</ul>
<p>Choose the right framework for every part of a model’s lifetime:</p>
<ul class="simple">
<li><p>Train state-of-the-art models in 3 lines of code</p></li>
<li><p>Deep interoperability between Jax, Pytorch and TensorFlow models</p></li>
<li><p>Move a single model between Jax/PyTorch/TensorFlow frameworks at will</p></li>
<li><p>Seamlessly pick the right framework for training, evaluation, production</p></li>
</ul>
<p>The support for Jax is still experimental (with a few models right now), expect to see it grow in the coming months!</p>
<p><a class="reference external" href="https://huggingface.co/models">All the model checkpoints</a> are seamlessly integrated from the huggingface.co <a class="reference external" href="https://huggingface.co">model
hub</a> where they are uploaded directly by <a class="reference external" href="https://huggingface.co/users">users</a> and
<a class="reference external" href="https://huggingface.co/organizations">organizations</a>.</p>
<p>Current number of checkpoints: <img alt="checkpoints" src="https://img.shields.io/endpoint?url=https://huggingface.co/api/shields/models&amp;color=brightgreen" /></p>
</div>
<div class="section" id="contents">
<h2>Contents<a class="headerlink" href="#contents" title="Permalink to this headline">¶</a></h2>
<p>The documentation is organized in five parts:</p>
<ul>
<li><p><strong>GET STARTED</strong> contains a quick tour, the installation instructions and some useful information about our philosophy
and a glossary.</p></li>
<li><p><strong>USING 🤗 TRANSFORMERS</strong> contains general tutorials on how to use the library.</p></li>
<li><p><strong>ADVANCED GUIDES</strong> contains more advanced guides that are more specific to a given script or part of the library.</p></li>
<li><p><strong>RESEARCH</strong> focuses on tutorials that have less to do with how to use the library but more about general research in
transformers model</p></li>
<li><p>The three last section contain the documentation of each public class and function, grouped in:</p>
<blockquote>
<div><ul class="simple">
<li><p><strong>MAIN CLASSES</strong> for the main classes exposing the important APIs of the library.</p></li>
<li><p><strong>MODELS</strong> for the classes and functions related to each model implemented in the library.</p></li>
<li><p><strong>INTERNAL HELPERS</strong> for the classes and functions we use internally.</p></li>
</ul>
</div></blockquote>
</li>
</ul>
<p>The library currently contains Jax, PyTorch and Tensorflow implementations, pretrained model weights, usage scripts and
conversion utilities for the following models:</p>
<ol class="arabic simple">
<li><p><a class="reference internal" href="model_doc/albert.html"><span class="doc">ALBERT</span></a> (from Google Research and the Toyota Technological Institute at Chicago) released
with the paper <a class="reference external" href="https://arxiv.org/abs/1909.11942">ALBERT: A Lite BERT for Self-supervised Learning of Language Representations</a>, by Zhenzhong Lan, Mingda Chen, Sebastian Goodman, Kevin Gimpel, Piyush
Sharma, Radu Soricut.</p></li>
<li><p><a class="reference internal" href="model_doc/bart.html"><span class="doc">BART</span></a> (from Facebook) released with the paper <a class="reference external" href="https://arxiv.org/pdf/1910.13461.pdf">BART: Denoising Sequence-to-Sequence
Pre-training for Natural Language Generation, Translation, and Comprehension</a> by Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman
Mohamed, Omer Levy, Ves Stoyanov and Luke Zettlemoyer.</p></li>
<li><p><a class="reference internal" href="model_doc/barthez.html"><span class="doc">BARThez</span></a> (from École polytechnique) released with the paper <a class="reference external" href="https://arxiv.org/abs/2010.12321">BARThez: a Skilled Pretrained
French Sequence-to-Sequence Model</a> by Moussa Kamal Eddine, Antoine J.-P.
Tixier, Michalis Vazirgiannis.</p></li>
<li><p><a class="reference internal" href="model_doc/bert.html"><span class="doc">BERT</span></a> (from Google) released with the paper <a class="reference external" href="https://arxiv.org/abs/1810.04805">BERT: Pre-training of Deep Bidirectional
Transformers for Language Understanding</a> by Jacob Devlin, Ming-Wei Chang,
Kenton Lee and Kristina Toutanova.</p></li>
<li><p><a class="reference internal" href="model_doc/bertgeneration.html"><span class="doc">BERT For Sequence Generation</span></a> (from Google) released with the paper <a class="reference external" href="https://arxiv.org/abs/1907.12461">Leveraging
Pre-trained Checkpoints for Sequence Generation Tasks</a> by Sascha Rothe, Shashi
Narayan, Aliaksei Severyn.</p></li>
<li><p><a class="reference internal" href="model_doc/bigbird.html"><span class="doc">BigBird-RoBERTa</span></a> (from Google Research) released with the paper <a class="reference external" href="https://arxiv.org/abs/2007.14062">Big Bird: Transformers
for Longer Sequences</a> by Manzil Zaheer, Guru Guruganesh, Avinava Dubey, Joshua
Ainslie, Chris Alberti, Santiago Ontanon, Philip Pham, Anirudh Ravula, Qifan Wang, Li Yang, Amr Ahmed.</p></li>
<li><p><a class="reference internal" href="model_doc/bigbird_pegasus.html"><span class="doc">BigBird-Pegasus</span></a> (from Google Research) released with the paper <a class="reference external" href="https://arxiv.org/abs/2007.14062">Big Bird:
Transformers for Longer Sequences</a> by Manzil Zaheer, Guru Guruganesh, Avinava
Dubey, Joshua Ainslie, Chris Alberti, Santiago Ontanon, Philip Pham, Anirudh Ravula, Qifan Wang, Li Yang, Amr Ahmed.</p></li>
<li><p><a class="reference internal" href="model_doc/blenderbot.html"><span class="doc">Blenderbot</span></a> (from Facebook) released with the paper <a class="reference external" href="https://arxiv.org/abs/2004.13637">Recipes for building an
open-domain chatbot</a> by Stephen Roller, Emily Dinan, Naman Goyal, Da Ju, Mary
Williamson, Yinhan Liu, Jing Xu, Myle Ott, Kurt Shuster, Eric M. Smith, Y-Lan Boureau, Jason Weston.</p></li>
<li><p><a class="reference internal" href="model_doc/blenderbot_small.html"><span class="doc">BlenderbotSmall</span></a> (from Facebook) released with the paper <a class="reference external" href="https://arxiv.org/abs/2004.13637">Recipes for building an
open-domain chatbot</a> by Stephen Roller, Emily Dinan, Naman Goyal, Da Ju, Mary
Williamson, Yinhan Liu, Jing Xu, Myle Ott, Kurt Shuster, Eric M. Smith, Y-Lan Boureau, Jason Weston.</p></li>
<li><p><a class="reference internal" href="model_doc/bort.html"><span class="doc">BORT</span></a> (from Alexa) released with the paper <a class="reference external" href="https://arxiv.org/abs/2010.10499">Optimal Subarchitecture Extraction For BERT</a> by Adrian de Wynter and Daniel J. Perry.</p></li>
<li><p><a class="reference internal" href="model_doc/camembert.html"><span class="doc">CamemBERT</span></a> (from Inria/Facebook/Sorbonne) released with the paper <a class="reference external" href="https://arxiv.org/abs/1911.03894">CamemBERT: a Tasty
French Language Model</a> by Louis Martin*, Benjamin Muller*, Pedro Javier Ortiz
Suárez*, Yoann Dupont, Laurent Romary, Éric Villemonte de la Clergerie, Djamé Seddah and Benoît Sagot.</p></li>
<li><p><a class="reference internal" href="model_doc/clip.html"><span class="doc">CLIP</span></a> from (OpenAI) released with the paper <a class="reference external" href="https://arxiv.org/abs/2103.00020">Learning Transferable Visual Models From
Natural Language Supervision</a> by Alec Radford, Jong Wook Kim, Chris Hallacy,
Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, Gretchen
Krueger, Ilya Sutskever.</p></li>
<li><p><a class="reference internal" href="model_doc/convbert.html"><span class="doc">ConvBERT</span></a> (from YituTech) released with the paper <a class="reference external" href="https://arxiv.org/abs/2008.02496">ConvBERT: Improving BERT with
Span-based Dynamic Convolution</a> by Zihang Jiang, Weihao Yu, Daquan Zhou,
Yunpeng Chen, Jiashi Feng, Shuicheng Yan.</p></li>
<li><p><a class="reference internal" href="model_doc/cpm.html"><span class="doc">CPM</span></a> (from Tsinghua University) released with the paper <a class="reference external" href="https://arxiv.org/abs/2012.00413">CPM: A Large-scale Generative
Chinese Pre-trained Language Model</a> by Zhengyan Zhang, Xu Han, Hao Zhou, Pei
Ke, Yuxian Gu, Deming Ye, Yujia Qin, Yusheng Su, Haozhe Ji, Jian Guan, Fanchao Qi, Xiaozhi Wang, Yanan Zheng,
Guoyang Zeng, Huanqi Cao, Shengqi Chen, Daixuan Li, Zhenbo Sun, Zhiyuan Liu, Minlie Huang, Wentao Han, Jie Tang,
Juanzi Li, Xiaoyan Zhu, Maosong Sun.</p></li>
<li><p><a class="reference internal" href="model_doc/ctrl.html"><span class="doc">CTRL</span></a> (from Salesforce) released with the paper <a class="reference external" href="https://arxiv.org/abs/1909.05858">CTRL: A Conditional Transformer Language
Model for Controllable Generation</a> by Nitish Shirish Keskar*, Bryan McCann*,
Lav R. Varshney, Caiming Xiong and Richard Socher.</p></li>
<li><p><a class="reference internal" href="model_doc/deberta.html"><span class="doc">DeBERTa</span></a> (from Microsoft) released with the paper <a class="reference external" href="https://arxiv.org/abs/2006.03654">DeBERTa: Decoding-enhanced BERT with
Disentangled Attention</a> by Pengcheng He, Xiaodong Liu, Jianfeng Gao, Weizhu
Chen.</p></li>
<li><p><a class="reference internal" href="model_doc/deberta_v2.html"><span class="doc">DeBERTa-v2</span></a> (from Microsoft) released with the paper <a class="reference external" href="https://arxiv.org/abs/2006.03654">DeBERTa: Decoding-enhanced BERT
with Disentangled Attention</a> by Pengcheng He, Xiaodong Liu, Jianfeng Gao,
Weizhu Chen.</p></li>
<li><p><a class="reference internal" href="model_doc/deit.html"><span class="doc">DeiT</span></a> (from Facebook) released with the paper <a class="reference external" href="https://arxiv.org/abs/2012.12877">Training data-efficient image transformers &amp;
distillation through attention</a> by Hugo Touvron, Matthieu Cord, Matthijs
Douze, Francisco Massa, Alexandre Sablayrolles, Hervé Jégou.</p></li>
<li><p><a class="reference internal" href="model_doc/dialogpt.html"><span class="doc">DialoGPT</span></a> (from Microsoft Research) released with the paper <a class="reference external" href="https://arxiv.org/abs/1911.00536">DialoGPT: Large-Scale
Generative Pre-training for Conversational Response Generation</a> by Yizhe
Zhang, Siqi Sun, Michel Galley, Yen-Chun Chen, Chris Brockett, Xiang Gao, Jianfeng Gao, Jingjing Liu, Bill Dolan.</p></li>
<li><p><a class="reference internal" href="model_doc/distilbert.html"><span class="doc">DistilBERT</span></a> (from HuggingFace), released together with the paper <a class="reference external" href="https://arxiv.org/abs/1910.01108">DistilBERT, a
distilled version of BERT: smaller, faster, cheaper and lighter</a> by Victor
Sanh, Lysandre Debut and Thomas Wolf. The same method has been applied to compress GPT2 into <a class="reference external" href="https://github.com/huggingface/transformers/tree/master/examples/distillation">DistilGPT2</a>, RoBERTa into <a class="reference external" href="https://github.com/huggingface/transformers/tree/master/examples/distillation">DistilRoBERTa</a>, Multilingual BERT into
<a class="reference external" href="https://github.com/huggingface/transformers/tree/master/examples/distillation">DistilmBERT</a> and a German
version of DistilBERT.</p></li>
<li><p><a class="reference internal" href="model_doc/dpr.html"><span class="doc">DPR</span></a> (from Facebook) released with the paper <a class="reference external" href="https://arxiv.org/abs/2004.04906">Dense Passage Retrieval for Open-Domain
Question Answering</a> by Vladimir Karpukhin, Barlas Oğuz, Sewon Min, Patrick
Lewis, Ledell Wu, Sergey Edunov, Danqi Chen, and Wen-tau Yih.</p></li>
<li><p><a class="reference internal" href="model_doc/electra.html"><span class="doc">ELECTRA</span></a> (from Google Research/Stanford University) released with the paper <a class="reference external" href="https://arxiv.org/abs/2003.10555">ELECTRA:
Pre-training text encoders as discriminators rather than generators</a> by Kevin
Clark, Minh-Thang Luong, Quoc V. Le, Christopher D. Manning.</p></li>
<li><p><a class="reference internal" href="model_doc/flaubert.html"><span class="doc">FlauBERT</span></a> (from CNRS) released with the paper <a class="reference external" href="https://arxiv.org/abs/1912.05372">FlauBERT: Unsupervised Language Model
Pre-training for French</a> by Hang Le, Loïc Vial, Jibril Frej, Vincent Segonne,
Maximin Coavoux, Benjamin Lecouteux, Alexandre Allauzen, Benoît Crabbé, Laurent Besacier, Didier Schwab.</p></li>
<li><p><a class="reference internal" href="model_doc/funnel.html"><span class="doc">Funnel Transformer</span></a> (from CMU/Google Brain) released with the paper <a class="reference external" href="https://arxiv.org/abs/2006.03236">Funnel-Transformer:
Filtering out Sequential Redundancy for Efficient Language Processing</a> by
Zihang Dai, Guokun Lai, Yiming Yang, Quoc V. Le.</p></li>
<li><p><a class="reference internal" href="model_doc/gpt.html"><span class="doc">GPT</span></a> (from OpenAI) released with the paper <a class="reference external" href="https://blog.openai.com/language-unsupervised/">Improving Language Understanding by Generative
Pre-Training</a> by Alec Radford, Karthik Narasimhan, Tim Salimans
and Ilya Sutskever.</p></li>
<li><p><a class="reference internal" href="model_doc/gpt2.html"><span class="doc">GPT-2</span></a> (from OpenAI) released with the paper <a class="reference external" href="https://blog.openai.com/better-language-models/">Language Models are Unsupervised Multitask
Learners</a> by Alec Radford*, Jeffrey Wu*, Rewon Child, David
Luan, Dario Amodei** and Ilya Sutskever**.</p></li>
<li><p><a class="reference internal" href="model_doc/gpt_neo.html"><span class="doc">GPT Neo</span></a> (from EleutherAI) released in the repository <a class="reference external" href="https://github.com/EleutherAI/gpt-neo">EleutherAI/gpt-neo</a> by Sid Black, Stella Biderman, Leo Gao, Phil Wang and Connor Leahy.</p></li>
<li><p><a class="reference internal" href="model_doc/ibert.html"><span class="doc">I-BERT</span></a> (from Berkeley) released with the paper <a class="reference external" href="https://arxiv.org/abs/2101.01321">I-BERT: Integer-only BERT Quantization</a> by Sehoon Kim, Amir Gholami, Zhewei Yao, Michael W. Mahoney, Kurt Keutzer</p></li>
<li><p><a class="reference internal" href="model_doc/layoutlm.html"><span class="doc">LayoutLM</span></a> (from Microsoft Research Asia) released with the paper <a class="reference external" href="https://arxiv.org/abs/1912.13318">LayoutLM: Pre-training
of Text and Layout for Document Image Understanding</a> by Yiheng Xu, Minghao Li,
Lei Cui, Shaohan Huang, Furu Wei, Ming Zhou.</p></li>
<li><p><a class="reference internal" href="model_doc/led.html"><span class="doc">LED</span></a> (from AllenAI) released with the paper <a class="reference external" href="https://arxiv.org/abs/2004.05150">Longformer: The Long-Document Transformer</a> by Iz Beltagy, Matthew E. Peters, Arman Cohan.</p></li>
<li><p><a class="reference internal" href="model_doc/longformer.html"><span class="doc">Longformer</span></a> (from AllenAI) released with the paper <a class="reference external" href="https://arxiv.org/abs/2004.05150">Longformer: The Long-Document
Transformer</a> by Iz Beltagy, Matthew E. Peters, Arman Cohan.</p></li>
<li><p><a class="reference internal" href="model_doc/luke.html"><span class="doc">LUKE</span></a> (from Studio Ousia) released with the paper <a class="reference external" href="https://arxiv.org/abs/2010.01057">LUKE: Deep Contextualized Entity
Representations with Entity-aware Self-attention</a> by Ikuya Yamada, Akari Asai,
Hiroyuki Shindo, Hideaki Takeda, Yuji Matsumoto.</p></li>
<li><p><a class="reference internal" href="model_doc/lxmert.html"><span class="doc">LXMERT</span></a> (from UNC Chapel Hill) released with the paper <a class="reference external" href="https://arxiv.org/abs/1908.07490">LXMERT: Learning Cross-Modality
Encoder Representations from Transformers for Open-Domain Question Answering</a>
by Hao Tan and Mohit Bansal.</p></li>
<li><p><a class="reference internal" href="model_doc/m2m_100.html"><span class="doc">M2M100</span></a> (from Facebook) released with the paper <a class="reference external" href="https://arxiv.org/abs/2010.11125">Beyond English-Centric Multilingual
Machine Translation</a> by by Angela Fan, Shruti Bhosale, Holger Schwenk, Zhiyi
Ma, Ahmed El-Kishky, Siddharth Goyal, Mandeep Baines, Onur Celebi, Guillaume Wenzek, Vishrav Chaudhary, Naman
Goyal, Tom Birch, Vitaliy Liptchinsky, Sergey Edunov, Edouard Grave, Michael Auli, Armand Joulin.</p></li>
<li><p><a class="reference internal" href="model_doc/marian.html"><span class="doc">MarianMT</span></a> Machine translation models trained using <a class="reference external" href="http://opus.nlpl.eu/">OPUS</a> data by
Jörg Tiedemann. The <a class="reference external" href="https://marian-nmt.github.io/">Marian Framework</a> is being developed by the Microsoft
Translator Team.</p></li>
<li><p><a class="reference internal" href="model_doc/mbart.html"><span class="doc">MBart</span></a> (from Facebook) released with the paper <a class="reference external" href="https://arxiv.org/abs/2001.08210">Multilingual Denoising Pre-training for
Neural Machine Translation</a> by Yinhan Liu, Jiatao Gu, Naman Goyal, Xian Li,
Sergey Edunov, Marjan Ghazvininejad, Mike Lewis, Luke Zettlemoyer.</p></li>
<li><p><a class="reference internal" href="model_doc/mbart.html"><span class="doc">MBart-50</span></a> (from Facebook) released with the paper <a class="reference external" href="https://arxiv.org/abs/2008.00401">Multilingual Translation with Extensible
Multilingual Pretraining and Finetuning</a> by Yuqing Tang, Chau Tran, Xian Li,
Peng-Jen Chen, Naman Goyal, Vishrav Chaudhary, Jiatao Gu, Angela Fan.</p></li>
<li><p><a class="reference internal" href="model_doc/megatron_bert.html"><span class="doc">Megatron-BERT</span></a> (from NVIDIA) released with the paper <a class="reference external" href="https://arxiv.org/abs/1909.08053">Megatron-LM: Training
Multi-Billion Parameter Language Models Using Model Parallelism</a> by Mohammad
Shoeybi, Mostofa Patwary, Raul Puri, Patrick LeGresley, Jared Casper and Bryan Catanzaro.</p></li>
<li><p><a class="reference internal" href="model_doc/megatron_gpt2.html"><span class="doc">Megatron-GPT2</span></a> (from NVIDIA) released with the paper <a class="reference external" href="https://arxiv.org/abs/1909.08053">Megatron-LM: Training
Multi-Billion Parameter Language Models Using Model Parallelism</a> by Mohammad
Shoeybi, Mostofa Patwary, Raul Puri, Patrick LeGresley, Jared Casper and Bryan Catanzaro.</p></li>
<li><p><a class="reference internal" href="model_doc/mpnet.html"><span class="doc">MPNet</span></a> (from Microsoft Research) released with the paper <a class="reference external" href="https://arxiv.org/abs/2004.09297">MPNet: Masked and Permuted
Pre-training for Language Understanding</a> by Kaitao Song, Xu Tan, Tao Qin,
Jianfeng Lu, Tie-Yan Liu.</p></li>
<li><p><a class="reference internal" href="model_doc/mt5.html"><span class="doc">MT5</span></a> (from Google AI) released with the paper <a class="reference external" href="https://arxiv.org/abs/2010.11934">mT5: A massively multilingual pre-trained
text-to-text transformer</a> by Linting Xue, Noah Constant, Adam Roberts, Mihir
Kale, Rami Al-Rfou, Aditya Siddhant, Aditya Barua, Colin Raffel.</p></li>
<li><p><a class="reference internal" href="model_doc/pegasus.html"><span class="doc">Pegasus</span></a> (from Google) released with the paper <a class="reference external" href="https://arxiv.org/abs/1912.08777">PEGASUS: Pre-training with Extracted
Gap-sentences for Abstractive Summarization</a>&gt; by Jingqing Zhang, Yao Zhao,
Mohammad Saleh and Peter J. Liu.</p></li>
<li><p><a class="reference internal" href="model_doc/prophetnet.html"><span class="doc">ProphetNet</span></a> (from Microsoft Research) released with the paper <a class="reference external" href="https://arxiv.org/abs/2001.04063">ProphetNet: Predicting
Future N-gram for Sequence-to-Sequence Pre-training</a> by Yu Yan, Weizhen Qi,
Yeyun Gong, Dayiheng Liu, Nan Duan, Jiusheng Chen, Ruofei Zhang and Ming Zhou.</p></li>
<li><p><a class="reference internal" href="model_doc/reformer.html"><span class="doc">Reformer</span></a> (from Google Research) released with the paper <a class="reference external" href="https://arxiv.org/abs/2001.04451">Reformer: The Efficient
Transformer</a> by Nikita Kitaev, Łukasz Kaiser, Anselm Levskaya.</p></li>
<li><p><a class="reference internal" href="model_doc/roberta.html"><span class="doc">RoBERTa</span></a> (from Facebook), released together with the paper a <a class="reference external" href="https://arxiv.org/abs/1907.11692">Robustly Optimized BERT
Pretraining Approach</a> by Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar
Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, Veselin Stoyanov.</p></li>
<li><p><a class="reference internal" href="model_doc/speech_to_text.html"><span class="doc">SpeechToTextTransformer</span></a> (from Facebook), released together with the paper
<a class="reference external" href="https://arxiv.org/abs/2010.05171">fairseq S2T: Fast Speech-to-Text Modeling with fairseq</a> by Changhan Wang, Yun
Tang, Xutai Ma, Anne Wu, Dmytro Okhonko, Juan Pino.</p></li>
<li><p><a class="reference internal" href="model_doc/squeezebert.html"><span class="doc">SqueezeBert</span></a> released with the paper <a class="reference external" href="https://arxiv.org/abs/2006.11316">SqueezeBERT: What can computer vision teach NLP
about efficient neural networks?</a> by Forrest N. Iandola, Albert E. Shaw, Ravi
Krishna, and Kurt W. Keutzer.</p></li>
<li><p><a class="reference internal" href="model_doc/t5.html"><span class="doc">T5</span></a> (from Google AI) released with the paper <a class="reference external" href="https://arxiv.org/abs/1910.10683">Exploring the Limits of Transfer Learning with a
Unified Text-to-Text Transformer</a> by Colin Raffel and Noam Shazeer and Adam
Roberts and Katherine Lee and Sharan Narang and Michael Matena and Yanqi Zhou and Wei Li and Peter J. Liu.</p></li>
<li><p><a class="reference internal" href="model_doc/tapas.html"><span class="doc">TAPAS</span></a> (from Google AI) released with the paper <a class="reference external" href="https://arxiv.org/abs/2004.02349">TAPAS: Weakly Supervised Table Parsing via
Pre-training</a> by Jonathan Herzig, Paweł Krzysztof Nowak, Thomas Müller,
Francesco Piccinno and Julian Martin Eisenschlos.</p></li>
<li><p><a class="reference internal" href="model_doc/transformerxl.html"><span class="doc">Transformer-XL</span></a> (from Google/CMU) released with the paper <a class="reference external" href="https://arxiv.org/abs/1901.02860">Transformer-XL:
Attentive Language Models Beyond a Fixed-Length Context</a> by Zihang Dai*,
Zhilin Yang*, Yiming Yang, Jaime Carbonell, Quoc V. Le, Ruslan Salakhutdinov.</p></li>
<li><p><a class="reference internal" href="model_doc/vit.html"><span class="doc">Vision Transformer (ViT)</span></a> (from Google AI) released with the paper <a class="reference external" href="https://arxiv.org/abs/2010.11929">An Image is Worth 16x16
Words: Transformers for Image Recognition at Scale</a> by Alexey Dosovitskiy,
Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias
Minderer, Georg Heigold, Sylvain Gelly, Jakob Uszkoreit, Neil Houlsby.</p></li>
<li><p><a class="reference internal" href="model_doc/wav2vec2.html"><span class="doc">Wav2Vec2</span></a> (from Facebook AI) released with the paper <a class="reference external" href="https://arxiv.org/abs/2006.11477">wav2vec 2.0: A Framework for
Self-Supervised Learning of Speech Representations</a> by Alexei Baevski, Henry
Zhou, Abdelrahman Mohamed, Michael Auli.</p></li>
<li><p><a class="reference internal" href="model_doc/xlm.html"><span class="doc">XLM</span></a> (from Facebook) released together with the paper <a class="reference external" href="https://arxiv.org/abs/1901.07291">Cross-lingual Language Model
Pretraining</a> by Guillaume Lample and Alexis Conneau.</p></li>
<li><p><a class="reference internal" href="model_doc/xlmprophetnet.html"><span class="doc">XLM-ProphetNet</span></a> (from Microsoft Research) released with the paper <a class="reference external" href="https://arxiv.org/abs/2001.04063">ProphetNet:
Predicting Future N-gram for Sequence-to-Sequence Pre-training</a> by Yu Yan,
Weizhen Qi, Yeyun Gong, Dayiheng Liu, Nan Duan, Jiusheng Chen, Ruofei Zhang and Ming Zhou.</p></li>
<li><p><a class="reference internal" href="model_doc/xlmroberta.html"><span class="doc">XLM-RoBERTa</span></a> (from Facebook AI), released together with the paper <a class="reference external" href="https://arxiv.org/abs/1911.02116">Unsupervised
Cross-lingual Representation Learning at Scale</a> by Alexis Conneau*, Kartikay
Khandelwal*, Naman Goyal, Vishrav Chaudhary, Guillaume Wenzek, Francisco Guzmán, Edouard Grave, Myle Ott, Luke
Zettlemoyer and Veselin Stoyanov.</p></li>
<li><p><a class="reference internal" href="model_doc/xlnet.html"><span class="doc">XLNet</span></a> (from Google/CMU) released with the paper <a class="reference external" href="https://arxiv.org/abs/1906.08237">​XLNet: Generalized Autoregressive
Pretraining for Language Understanding</a> by Zhilin Yang*, Zihang Dai*, Yiming
Yang, Jaime Carbonell, Ruslan Salakhutdinov, Quoc V. Le.</p></li>
<li><p><a class="reference internal" href="model_doc/xlsr_wav2vec2.html"><span class="doc">XLSR-Wav2Vec2</span></a> (from Facebook AI) released with the paper <a class="reference external" href="https://arxiv.org/abs/2006.13979">Unsupervised
Cross-Lingual Representation Learning For Speech Recognition</a> by Alexis
Conneau, Alexei Baevski, Ronan Collobert, Abdelrahman Mohamed, Michael Auli.</p></li>
</ol>
<p id="bigtable">The table below represents the current support in the library for each of those models, whether they have a Python
tokenizer (called “slow”). A “fast” tokenizer backed by the 🤗 Tokenizers library, whether they have support in Jax (via
Flax), PyTorch, and/or TensorFlow.</p>
<table class="center-aligned-table docutils align-default">
<colgroup>
<col style="width: 26%" />
<col style="width: 14%" />
<col style="width: 14%" />
<col style="width: 15%" />
<col style="width: 18%" />
<col style="width: 13%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Model</p></th>
<th class="head"><p>Tokenizer slow</p></th>
<th class="head"><p>Tokenizer fast</p></th>
<th class="head"><p>PyTorch support</p></th>
<th class="head"><p>TensorFlow support</p></th>
<th class="head"><p>Flax Support</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>ALBERT</p></td>
<td><p>✅</p></td>
<td><p>✅</p></td>
<td><p>✅</p></td>
<td><p>✅</p></td>
<td><p>❌</p></td>
</tr>
<tr class="row-odd"><td><p>BART</p></td>
<td><p>✅</p></td>
<td><p>✅</p></td>
<td><p>✅</p></td>
<td><p>✅</p></td>
<td><p>❌</p></td>
</tr>
<tr class="row-even"><td><p>BERT</p></td>
<td><p>✅</p></td>
<td><p>✅</p></td>
<td><p>✅</p></td>
<td><p>✅</p></td>
<td><p>✅</p></td>
</tr>
<tr class="row-odd"><td><p>Bert Generation</p></td>
<td><p>✅</p></td>
<td><p>❌</p></td>
<td><p>✅</p></td>
<td><p>❌</p></td>
<td><p>❌</p></td>
</tr>
<tr class="row-even"><td><p>BigBird</p></td>
<td><p>✅</p></td>
<td><p>✅</p></td>
<td><p>✅</p></td>
<td><p>❌</p></td>
<td><p>❌</p></td>
</tr>
<tr class="row-odd"><td><p>BigBirdPegasus</p></td>
<td><p>❌</p></td>
<td><p>❌</p></td>
<td><p>✅</p></td>
<td><p>❌</p></td>
<td><p>❌</p></td>
</tr>
<tr class="row-even"><td><p>Blenderbot</p></td>
<td><p>✅</p></td>
<td><p>❌</p></td>
<td><p>✅</p></td>
<td><p>✅</p></td>
<td><p>❌</p></td>
</tr>
<tr class="row-odd"><td><p>BlenderbotSmall</p></td>
<td><p>✅</p></td>
<td><p>❌</p></td>
<td><p>✅</p></td>
<td><p>✅</p></td>
<td><p>❌</p></td>
</tr>
<tr class="row-even"><td><p>CLIP</p></td>
<td><p>✅</p></td>
<td><p>✅</p></td>
<td><p>✅</p></td>
<td><p>❌</p></td>
<td><p>❌</p></td>
</tr>
<tr class="row-odd"><td><p>CTRL</p></td>
<td><p>✅</p></td>
<td><p>❌</p></td>
<td><p>✅</p></td>
<td><p>✅</p></td>
<td><p>❌</p></td>
</tr>
<tr class="row-even"><td><p>CamemBERT</p></td>
<td><p>✅</p></td>
<td><p>✅</p></td>
<td><p>✅</p></td>
<td><p>✅</p></td>
<td><p>❌</p></td>
</tr>
<tr class="row-odd"><td><p>ConvBERT</p></td>
<td><p>✅</p></td>
<td><p>✅</p></td>
<td><p>✅</p></td>
<td><p>✅</p></td>
<td><p>❌</p></td>
</tr>
<tr class="row-even"><td><p>DPR</p></td>
<td><p>✅</p></td>
<td><p>✅</p></td>
<td><p>✅</p></td>
<td><p>✅</p></td>
<td><p>❌</p></td>
</tr>
<tr class="row-odd"><td><p>DeBERTa</p></td>
<td><p>✅</p></td>
<td><p>✅</p></td>
<td><p>✅</p></td>
<td><p>❌</p></td>
<td><p>❌</p></td>
</tr>
<tr class="row-even"><td><p>DeBERTa-v2</p></td>
<td><p>✅</p></td>
<td><p>❌</p></td>
<td><p>✅</p></td>
<td><p>❌</p></td>
<td><p>❌</p></td>
</tr>
<tr class="row-odd"><td><p>DeiT</p></td>
<td><p>❌</p></td>
<td><p>❌</p></td>
<td><p>✅</p></td>
<td><p>❌</p></td>
<td><p>❌</p></td>
</tr>
<tr class="row-even"><td><p>DistilBERT</p></td>
<td><p>✅</p></td>
<td><p>✅</p></td>
<td><p>✅</p></td>
<td><p>✅</p></td>
<td><p>❌</p></td>
</tr>
<tr class="row-odd"><td><p>ELECTRA</p></td>
<td><p>✅</p></td>
<td><p>✅</p></td>
<td><p>✅</p></td>
<td><p>✅</p></td>
<td><p>✅</p></td>
</tr>
<tr class="row-even"><td><p>Encoder decoder</p></td>
<td><p>❌</p></td>
<td><p>❌</p></td>
<td><p>✅</p></td>
<td><p>❌</p></td>
<td><p>❌</p></td>
</tr>
<tr class="row-odd"><td><p>FairSeq Machine-Translation</p></td>
<td><p>✅</p></td>
<td><p>❌</p></td>
<td><p>✅</p></td>
<td><p>❌</p></td>
<td><p>❌</p></td>
</tr>
<tr class="row-even"><td><p>FlauBERT</p></td>
<td><p>✅</p></td>
<td><p>❌</p></td>
<td><p>✅</p></td>
<td><p>✅</p></td>
<td><p>❌</p></td>
</tr>
<tr class="row-odd"><td><p>Funnel Transformer</p></td>
<td><p>✅</p></td>
<td><p>✅</p></td>
<td><p>✅</p></td>
<td><p>✅</p></td>
<td><p>❌</p></td>
</tr>
<tr class="row-even"><td><p>GPT Neo</p></td>
<td><p>❌</p></td>
<td><p>❌</p></td>
<td><p>✅</p></td>
<td><p>❌</p></td>
<td><p>❌</p></td>
</tr>
<tr class="row-odd"><td><p>I-BERT</p></td>
<td><p>❌</p></td>
<td><p>❌</p></td>
<td><p>✅</p></td>
<td><p>❌</p></td>
<td><p>❌</p></td>
</tr>
<tr class="row-even"><td><p>LED</p></td>
<td><p>✅</p></td>
<td><p>✅</p></td>
<td><p>✅</p></td>
<td><p>✅</p></td>
<td><p>❌</p></td>
</tr>
<tr class="row-odd"><td><p>LUKE</p></td>
<td><p>✅</p></td>
<td><p>❌</p></td>
<td><p>✅</p></td>
<td><p>❌</p></td>
<td><p>❌</p></td>
</tr>
<tr class="row-even"><td><p>LXMERT</p></td>
<td><p>✅</p></td>
<td><p>✅</p></td>
<td><p>✅</p></td>
<td><p>✅</p></td>
<td><p>❌</p></td>
</tr>
<tr class="row-odd"><td><p>LayoutLM</p></td>
<td><p>✅</p></td>
<td><p>✅</p></td>
<td><p>✅</p></td>
<td><p>✅</p></td>
<td><p>❌</p></td>
</tr>
<tr class="row-even"><td><p>Longformer</p></td>
<td><p>✅</p></td>
<td><p>✅</p></td>
<td><p>✅</p></td>
<td><p>✅</p></td>
<td><p>❌</p></td>
</tr>
<tr class="row-odd"><td><p>M2M100</p></td>
<td><p>✅</p></td>
<td><p>❌</p></td>
<td><p>✅</p></td>
<td><p>❌</p></td>
<td><p>❌</p></td>
</tr>
<tr class="row-even"><td><p>MPNet</p></td>
<td><p>✅</p></td>
<td><p>✅</p></td>
<td><p>✅</p></td>
<td><p>✅</p></td>
<td><p>❌</p></td>
</tr>
<tr class="row-odd"><td><p>Marian</p></td>
<td><p>✅</p></td>
<td><p>❌</p></td>
<td><p>✅</p></td>
<td><p>✅</p></td>
<td><p>❌</p></td>
</tr>
<tr class="row-even"><td><p>MegatronBert</p></td>
<td><p>❌</p></td>
<td><p>❌</p></td>
<td><p>✅</p></td>
<td><p>❌</p></td>
<td><p>❌</p></td>
</tr>
<tr class="row-odd"><td><p>MobileBERT</p></td>
<td><p>✅</p></td>
<td><p>✅</p></td>
<td><p>✅</p></td>
<td><p>✅</p></td>
<td><p>❌</p></td>
</tr>
<tr class="row-even"><td><p>OpenAI GPT</p></td>
<td><p>✅</p></td>
<td><p>✅</p></td>
<td><p>✅</p></td>
<td><p>✅</p></td>
<td><p>❌</p></td>
</tr>
<tr class="row-odd"><td><p>OpenAI GPT-2</p></td>
<td><p>✅</p></td>
<td><p>✅</p></td>
<td><p>✅</p></td>
<td><p>✅</p></td>
<td><p>❌</p></td>
</tr>
<tr class="row-even"><td><p>Pegasus</p></td>
<td><p>✅</p></td>
<td><p>✅</p></td>
<td><p>✅</p></td>
<td><p>✅</p></td>
<td><p>❌</p></td>
</tr>
<tr class="row-odd"><td><p>ProphetNet</p></td>
<td><p>✅</p></td>
<td><p>❌</p></td>
<td><p>✅</p></td>
<td><p>❌</p></td>
<td><p>❌</p></td>
</tr>
<tr class="row-even"><td><p>RAG</p></td>
<td><p>✅</p></td>
<td><p>❌</p></td>
<td><p>✅</p></td>
<td><p>✅</p></td>
<td><p>❌</p></td>
</tr>
<tr class="row-odd"><td><p>Reformer</p></td>
<td><p>✅</p></td>
<td><p>✅</p></td>
<td><p>✅</p></td>
<td><p>❌</p></td>
<td><p>❌</p></td>
</tr>
<tr class="row-even"><td><p>RetriBERT</p></td>
<td><p>✅</p></td>
<td><p>✅</p></td>
<td><p>✅</p></td>
<td><p>❌</p></td>
<td><p>❌</p></td>
</tr>
<tr class="row-odd"><td><p>RoBERTa</p></td>
<td><p>✅</p></td>
<td><p>✅</p></td>
<td><p>✅</p></td>
<td><p>✅</p></td>
<td><p>✅</p></td>
</tr>
<tr class="row-even"><td><p>Speech2Text</p></td>
<td><p>✅</p></td>
<td><p>❌</p></td>
<td><p>✅</p></td>
<td><p>❌</p></td>
<td><p>❌</p></td>
</tr>
<tr class="row-odd"><td><p>SqueezeBERT</p></td>
<td><p>✅</p></td>
<td><p>✅</p></td>
<td><p>✅</p></td>
<td><p>❌</p></td>
<td><p>❌</p></td>
</tr>
<tr class="row-even"><td><p>T5</p></td>
<td><p>✅</p></td>
<td><p>✅</p></td>
<td><p>✅</p></td>
<td><p>✅</p></td>
<td><p>❌</p></td>
</tr>
<tr class="row-odd"><td><p>TAPAS</p></td>
<td><p>✅</p></td>
<td><p>❌</p></td>
<td><p>✅</p></td>
<td><p>❌</p></td>
<td><p>❌</p></td>
</tr>
<tr class="row-even"><td><p>Transformer-XL</p></td>
<td><p>✅</p></td>
<td><p>❌</p></td>
<td><p>✅</p></td>
<td><p>✅</p></td>
<td><p>❌</p></td>
</tr>
<tr class="row-odd"><td><p>ViT</p></td>
<td><p>❌</p></td>
<td><p>❌</p></td>
<td><p>✅</p></td>
<td><p>❌</p></td>
<td><p>❌</p></td>
</tr>
<tr class="row-even"><td><p>Wav2Vec2</p></td>
<td><p>✅</p></td>
<td><p>❌</p></td>
<td><p>✅</p></td>
<td><p>❌</p></td>
<td><p>❌</p></td>
</tr>
<tr class="row-odd"><td><p>XLM</p></td>
<td><p>✅</p></td>
<td><p>❌</p></td>
<td><p>✅</p></td>
<td><p>✅</p></td>
<td><p>❌</p></td>
</tr>
<tr class="row-even"><td><p>XLM-RoBERTa</p></td>
<td><p>✅</p></td>
<td><p>✅</p></td>
<td><p>✅</p></td>
<td><p>✅</p></td>
<td><p>❌</p></td>
</tr>
<tr class="row-odd"><td><p>XLMProphetNet</p></td>
<td><p>✅</p></td>
<td><p>❌</p></td>
<td><p>✅</p></td>
<td><p>❌</p></td>
<td><p>❌</p></td>
</tr>
<tr class="row-even"><td><p>XLNet</p></td>
<td><p>✅</p></td>
<td><p>✅</p></td>
<td><p>✅</p></td>
<td><p>✅</p></td>
<td><p>❌</p></td>
</tr>
<tr class="row-odd"><td><p>mBART</p></td>
<td><p>✅</p></td>
<td><p>✅</p></td>
<td><p>✅</p></td>
<td><p>✅</p></td>
<td><p>❌</p></td>
</tr>
<tr class="row-even"><td><p>mT5</p></td>
<td><p>✅</p></td>
<td><p>✅</p></td>
<td><p>✅</p></td>
<td><p>✅</p></td>
<td><p>❌</p></td>
</tr>
</tbody>
</table>
<div class="toctree-wrapper compound">
<p class="caption"><span class="caption-text">Get started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="quicktour.html">Quick tour</a><ul>
<li class="toctree-l2"><a class="reference internal" href="quicktour.html#getting-started-on-a-task-with-a-pipeline">Getting started on a task with a pipeline</a></li>
<li class="toctree-l2"><a class="reference internal" href="quicktour.html#under-the-hood-pretrained-models">Under the hood: pretrained models</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="installation.html">Installation</a><ul>
<li class="toctree-l2"><a class="reference internal" href="installation.html#installation-with-pip">Installation with pip</a></li>
<li class="toctree-l2"><a class="reference internal" href="installation.html#installing-from-source">Installing from source</a></li>
<li class="toctree-l2"><a class="reference internal" href="installation.html#editable-install">Editable install</a></li>
<li class="toctree-l2"><a class="reference internal" href="installation.html#with-conda">With conda</a></li>
<li class="toctree-l2"><a class="reference internal" href="installation.html#caching-models">Caching models</a></li>
<li class="toctree-l2"><a class="reference internal" href="installation.html#do-you-want-to-run-a-transformer-model-on-a-mobile-device">Do you want to run a Transformer model on a mobile device?</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="philosophy.html">Philosophy</a><ul>
<li class="toctree-l2"><a class="reference internal" href="philosophy.html#main-concepts">Main concepts</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="glossary.html">Glossary</a><ul>
<li class="toctree-l2"><a class="reference internal" href="glossary.html#general-terms">General terms</a></li>
<li class="toctree-l2"><a class="reference internal" href="glossary.html#model-inputs">Model inputs</a></li>
</ul>
</li>
</ul>
</div>
<div class="toctree-wrapper compound">
<p class="caption"><span class="caption-text">Using 🤗 Transformers</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="task_summary.html">Summary of the tasks</a><ul>
<li class="toctree-l2"><a class="reference internal" href="task_summary.html#sequence-classification">Sequence Classification</a></li>
<li class="toctree-l2"><a class="reference internal" href="task_summary.html#extractive-question-answering">Extractive Question Answering</a></li>
<li class="toctree-l2"><a class="reference internal" href="task_summary.html#language-modeling">Language Modeling</a></li>
<li class="toctree-l2"><a class="reference internal" href="task_summary.html#named-entity-recognition">Named Entity Recognition</a></li>
<li class="toctree-l2"><a class="reference internal" href="task_summary.html#summarization">Summarization</a></li>
<li class="toctree-l2"><a class="reference internal" href="task_summary.html#translation">Translation</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="model_summary.html">Summary of the models</a><ul>
<li class="toctree-l2"><a class="reference internal" href="model_summary.html#autoregressive-models">Autoregressive models</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_summary.html#autoencoding-models">Autoencoding models</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_summary.html#sequence-to-sequence-models">Sequence-to-sequence models</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_summary.html#multimodal-models">Multimodal models</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_summary.html#retrieval-based-models">Retrieval-based models</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_summary.html#more-technical-aspects">More technical aspects</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="preprocessing.html">Preprocessing data</a><ul>
<li class="toctree-l2"><a class="reference internal" href="preprocessing.html#base-use">Base use</a></li>
<li class="toctree-l2"><a class="reference internal" href="preprocessing.html#preprocessing-pairs-of-sentences">Preprocessing pairs of sentences</a></li>
<li class="toctree-l2"><a class="reference internal" href="preprocessing.html#everything-you-always-wanted-to-know-about-padding-and-truncation">Everything you always wanted to know about padding and truncation</a></li>
<li class="toctree-l2"><a class="reference internal" href="preprocessing.html#pre-tokenized-inputs">Pre-tokenized inputs</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="training.html">Fine-tuning a pretrained model</a><ul>
<li class="toctree-l2"><a class="reference internal" href="training.html#preparing-the-datasets">Preparing the datasets</a></li>
<li class="toctree-l2"><a class="reference internal" href="training.html#fine-tuning-in-pytorch-with-the-trainer-api">Fine-tuning in PyTorch with the Trainer API</a></li>
<li class="toctree-l2"><a class="reference internal" href="training.html#fine-tuning-with-keras">Fine-tuning with Keras</a></li>
<li class="toctree-l2"><a class="reference internal" href="training.html#fine-tuning-in-native-pytorch">Fine-tuning in native PyTorch</a></li>
<li class="toctree-l2"><a class="reference internal" href="training.html#additional-resources">Additional resources</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="model_sharing.html">Model sharing and uploading</a><ul>
<li class="toctree-l2"><a class="reference internal" href="model_sharing.html#model-versioning">Model versioning</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_sharing.html#push-your-model-from-python">Push your model from Python</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_sharing.html#use-your-terminal-and-git">Use your terminal and git</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_sharing.html#uploading-your-files">Uploading your files</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_sharing.html#workflow-in-a-colab-notebook">Workflow in a Colab notebook</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="tokenizer_summary.html">Summary of the tokenizers</a><ul>
<li class="toctree-l2"><a class="reference internal" href="tokenizer_summary.html#introduction">Introduction</a></li>
<li class="toctree-l2"><a class="reference internal" href="tokenizer_summary.html#byte-pair-encoding-bpe">Byte-Pair Encoding (BPE)</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="multilingual.html">Multi-lingual models</a><ul>
<li class="toctree-l2"><a class="reference internal" href="multilingual.html#xlm">XLM</a></li>
<li class="toctree-l2"><a class="reference internal" href="multilingual.html#bert">BERT</a></li>
<li class="toctree-l2"><a class="reference internal" href="multilingual.html#xlm-roberta">XLM-RoBERTa</a></li>
</ul>
</li>
</ul>
</div>
<div class="toctree-wrapper compound">
<p class="caption"><span class="caption-text">Advanced guides</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="pretrained_models.html">Pretrained models</a></li>
<li class="toctree-l1"><a class="reference internal" href="examples.html">Examples</a><ul>
<li class="toctree-l2"><a class="reference internal" href="examples.html#important-note">Important note</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="troubleshooting.html">Troubleshooting</a><ul>
<li class="toctree-l2"><a class="reference internal" href="troubleshooting.html#firewalled-environments">Firewalled environments</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="custom_datasets.html">Fine-tuning with custom datasets</a><ul>
<li class="toctree-l2"><a class="reference internal" href="custom_datasets.html#sequence-classification-with-imdb-reviews">Sequence Classification with IMDb Reviews</a></li>
<li class="toctree-l2"><a class="reference internal" href="custom_datasets.html#token-classification-with-w-nut-emerging-entities">Token Classification with W-NUT Emerging Entities</a></li>
<li class="toctree-l2"><a class="reference internal" href="custom_datasets.html#question-answering-with-squad-2-0">Question Answering with SQuAD 2.0</a></li>
<li class="toctree-l2"><a class="reference internal" href="custom_datasets.html#additional-resources">Additional Resources</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="notebooks.html">🤗 Transformers Notebooks</a><ul>
<li class="toctree-l2"><a class="reference internal" href="notebooks.html#hugging-face-s-notebooks">Hugging Face’s notebooks 🤗</a></li>
<li class="toctree-l2"><a class="reference internal" href="notebooks.html#community-notebooks">Community notebooks:</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="sagemaker.html">Run training on Amazon SageMaker</a><ul>
<li class="toctree-l2"><a class="reference internal" href="sagemaker.html#deep-learning-container-dlc-overview">Deep Learning Container (DLC) overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="sagemaker.html#getting-started-train-a-transformers-model">Getting Started: Train a 🤗 Transformers Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="sagemaker.html#sample-notebooks">Sample Notebooks</a></li>
<li class="toctree-l2"><a class="reference internal" href="sagemaker.html#advanced-features">Advanced Features</a></li>
<li class="toctree-l2"><a class="reference internal" href="sagemaker.html#additional-resources">Additional Resources</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="community.html">Community</a><ul>
<li class="toctree-l2"><a class="reference internal" href="community.html#community-resources">Community resources:</a></li>
<li class="toctree-l2"><a class="reference internal" href="community.html#community-notebooks">Community notebooks:</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="converting_tensorflow_models.html">Converting Tensorflow Checkpoints</a><ul>
<li class="toctree-l2"><a class="reference internal" href="converting_tensorflow_models.html#bert">BERT</a></li>
<li class="toctree-l2"><a class="reference internal" href="converting_tensorflow_models.html#albert">ALBERT</a></li>
<li class="toctree-l2"><a class="reference internal" href="converting_tensorflow_models.html#openai-gpt">OpenAI GPT</a></li>
<li class="toctree-l2"><a class="reference internal" href="converting_tensorflow_models.html#openai-gpt-2">OpenAI GPT-2</a></li>
<li class="toctree-l2"><a class="reference internal" href="converting_tensorflow_models.html#transformer-xl">Transformer-XL</a></li>
<li class="toctree-l2"><a class="reference internal" href="converting_tensorflow_models.html#xlnet">XLNet</a></li>
<li class="toctree-l2"><a class="reference internal" href="converting_tensorflow_models.html#xlm">XLM</a></li>
<li class="toctree-l2"><a class="reference internal" href="converting_tensorflow_models.html#t5">T5</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="migration.html">Migrating from previous packages</a><ul>
<li class="toctree-l2"><a class="reference internal" href="migration.html#migrating-from-transformers-v3-x-to-v4-x">Migrating from transformers <code class="docutils literal notranslate"><span class="pre">v3.x</span></code> to <code class="docutils literal notranslate"><span class="pre">v4.x</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="migration.html#migrating-from-pytorch-transformers-to-transformers">Migrating from pytorch-transformers to 🤗 Transformers</a></li>
<li class="toctree-l2"><a class="reference internal" href="migration.html#migrating-from-pytorch-pretrained-bert">Migrating from pytorch-pretrained-bert</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="contributing.html">How to contribute to transformers?</a><ul>
<li class="toctree-l2"><a class="reference internal" href="contributing.html#you-can-contribute-in-so-many-ways">You can contribute in so many ways!</a></li>
<li class="toctree-l2"><a class="reference internal" href="contributing.html#submitting-a-new-issue-or-feature-request">Submitting a new issue or feature request</a></li>
<li class="toctree-l2"><a class="reference internal" href="contributing.html#start-contributing-pull-requests">Start contributing! (Pull Requests)</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="add_new_model.html">How to add a model to 🤗 Transformers?</a><ul>
<li class="toctree-l2"><a class="reference internal" href="add_new_model.html#general-overview-of-transformers">General overview of 🤗 Transformers</a></li>
<li class="toctree-l2"><a class="reference internal" href="add_new_model.html#step-by-step-recipe-to-add-a-model-to-transformers">Step-by-step recipe to add a model to 🤗 Transformers</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="fast_tokenizers.html">Using tokenizers from 🤗 Tokenizers</a><ul>
<li class="toctree-l2"><a class="reference internal" href="fast_tokenizers.html#loading-directly-from-the-tokenizer-object">Loading directly from the tokenizer object</a></li>
<li class="toctree-l2"><a class="reference internal" href="fast_tokenizers.html#loading-from-a-json-file">Loading from a JSON file</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="testing.html">Testing</a><ul>
<li class="toctree-l2"><a class="reference internal" href="testing.html#how-transformers-are-tested">How transformers are tested</a></li>
<li class="toctree-l2"><a class="reference internal" href="testing.html#running-tests">Running tests</a></li>
<li class="toctree-l2"><a class="reference internal" href="testing.html#writing-tests">Writing tests</a></li>
<li class="toctree-l2"><a class="reference internal" href="testing.html#testing-experimental-ci-features">Testing Experimental CI Features</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="debugging.html">Debugging</a><ul>
<li class="toctree-l2"><a class="reference internal" href="debugging.html#underflow-and-overflow-detection">Underflow and Overflow Detection</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="serialization.html">Exporting transformers models</a><ul>
<li class="toctree-l2"><a class="reference internal" href="serialization.html#onnx-onnxruntime">ONNX / ONNXRuntime</a></li>
<li class="toctree-l2"><a class="reference internal" href="serialization.html#torchscript">TorchScript</a></li>
</ul>
</li>
</ul>
</div>
<div class="toctree-wrapper compound">
<p class="caption"><span class="caption-text">Research</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="bertology.html">BERTology</a></li>
<li class="toctree-l1"><a class="reference internal" href="perplexity.html">Perplexity of fixed-length models</a><ul>
<li class="toctree-l2"><a class="reference internal" href="perplexity.html#calculating-ppl-with-fixed-length-models">Calculating PPL with fixed-length models</a></li>
<li class="toctree-l2"><a class="reference internal" href="perplexity.html#example-calculating-perplexity-with-gpt-2-in-transformers">Example: Calculating perplexity with GPT-2 in 🤗 Transformers</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="benchmarks.html">Benchmarks</a><ul>
<li class="toctree-l2"><a class="reference internal" href="benchmarks.html#how-to-benchmark-transformer-models">How to benchmark 🤗 Transformer models</a></li>
<li class="toctree-l2"><a class="reference internal" href="benchmarks.html#benchmark-best-practices">Benchmark best practices</a></li>
<li class="toctree-l2"><a class="reference internal" href="benchmarks.html#sharing-your-benchmark">Sharing your benchmark</a></li>
</ul>
</li>
</ul>
</div>
<div class="toctree-wrapper compound">
<p class="caption"><span class="caption-text">Main Classes</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="main_classes/callback.html">Callbacks</a><ul>
<li class="toctree-l2"><a class="reference internal" href="main_classes/callback.html#available-callbacks">Available Callbacks</a></li>
<li class="toctree-l2"><a class="reference internal" href="main_classes/callback.html#trainercallback">TrainerCallback</a></li>
<li class="toctree-l2"><a class="reference internal" href="main_classes/callback.html#trainerstate">TrainerState</a></li>
<li class="toctree-l2"><a class="reference internal" href="main_classes/callback.html#trainercontrol">TrainerControl</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="main_classes/configuration.html">Configuration</a><ul>
<li class="toctree-l2"><a class="reference internal" href="main_classes/configuration.html#pretrainedconfig">PretrainedConfig</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="main_classes/data_collator.html">Data Collator</a><ul>
<li class="toctree-l2"><a class="reference internal" href="main_classes/data_collator.html#default-data-collator">Default data collator</a></li>
<li class="toctree-l2"><a class="reference internal" href="main_classes/data_collator.html#datacollatorwithpadding">DataCollatorWithPadding</a></li>
<li class="toctree-l2"><a class="reference internal" href="main_classes/data_collator.html#datacollatorfortokenclassification">DataCollatorForTokenClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="main_classes/data_collator.html#datacollatorforseq2seq">DataCollatorForSeq2Seq</a></li>
<li class="toctree-l2"><a class="reference internal" href="main_classes/data_collator.html#datacollatorforlanguagemodeling">DataCollatorForLanguageModeling</a></li>
<li class="toctree-l2"><a class="reference internal" href="main_classes/data_collator.html#datacollatorforwholewordmask">DataCollatorForWholeWordMask</a></li>
<li class="toctree-l2"><a class="reference internal" href="main_classes/data_collator.html#datacollatorforpermutationlanguagemodeling">DataCollatorForPermutationLanguageModeling</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="main_classes/logging.html">Logging</a><ul>
<li class="toctree-l2"><a class="reference internal" href="main_classes/logging.html#base-setters">Base setters</a></li>
<li class="toctree-l2"><a class="reference internal" href="main_classes/logging.html#other-functions">Other functions</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="main_classes/model.html">Models</a><ul>
<li class="toctree-l2"><a class="reference internal" href="main_classes/model.html#pretrainedmodel">PreTrainedModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="main_classes/model.html#moduleutilsmixin">ModuleUtilsMixin</a></li>
<li class="toctree-l2"><a class="reference internal" href="main_classes/model.html#tfpretrainedmodel">TFPreTrainedModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="main_classes/model.html#tfmodelutilsmixin">TFModelUtilsMixin</a></li>
<li class="toctree-l2"><a class="reference internal" href="main_classes/model.html#flaxpretrainedmodel">FlaxPreTrainedModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="main_classes/model.html#generation">Generation</a></li>
<li class="toctree-l2"><a class="reference internal" href="main_classes/model.html#pushing-to-the-hub">Pushing to the Hub</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="main_classes/optimizer_schedules.html">Optimization</a><ul>
<li class="toctree-l2"><a class="reference internal" href="main_classes/optimizer_schedules.html#adamw-pytorch">AdamW (PyTorch)</a></li>
<li class="toctree-l2"><a class="reference internal" href="main_classes/optimizer_schedules.html#adafactor-pytorch">AdaFactor (PyTorch)</a></li>
<li class="toctree-l2"><a class="reference internal" href="main_classes/optimizer_schedules.html#adamweightdecay-tensorflow">AdamWeightDecay (TensorFlow)</a></li>
<li class="toctree-l2"><a class="reference internal" href="main_classes/optimizer_schedules.html#schedules">Schedules</a></li>
<li class="toctree-l2"><a class="reference internal" href="main_classes/optimizer_schedules.html#gradient-strategies">Gradient Strategies</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="main_classes/output.html">Model outputs</a><ul>
<li class="toctree-l2"><a class="reference internal" href="main_classes/output.html#modeloutput">ModelOutput</a></li>
<li class="toctree-l2"><a class="reference internal" href="main_classes/output.html#basemodeloutput">BaseModelOutput</a></li>
<li class="toctree-l2"><a class="reference internal" href="main_classes/output.html#basemodeloutputwithpooling">BaseModelOutputWithPooling</a></li>
<li class="toctree-l2"><a class="reference internal" href="main_classes/output.html#basemodeloutputwithcrossattentions">BaseModelOutputWithCrossAttentions</a></li>
<li class="toctree-l2"><a class="reference internal" href="main_classes/output.html#basemodeloutputwithpoolingandcrossattentions">BaseModelOutputWithPoolingAndCrossAttentions</a></li>
<li class="toctree-l2"><a class="reference internal" href="main_classes/output.html#basemodeloutputwithpast">BaseModelOutputWithPast</a></li>
<li class="toctree-l2"><a class="reference internal" href="main_classes/output.html#basemodeloutputwithpastandcrossattentions">BaseModelOutputWithPastAndCrossAttentions</a></li>
<li class="toctree-l2"><a class="reference internal" href="main_classes/output.html#seq2seqmodeloutput">Seq2SeqModelOutput</a></li>
<li class="toctree-l2"><a class="reference internal" href="main_classes/output.html#causallmoutput">CausalLMOutput</a></li>
<li class="toctree-l2"><a class="reference internal" href="main_classes/output.html#causallmoutputwithcrossattentions">CausalLMOutputWithCrossAttentions</a></li>
<li class="toctree-l2"><a class="reference internal" href="main_classes/output.html#causallmoutputwithpast">CausalLMOutputWithPast</a></li>
<li class="toctree-l2"><a class="reference internal" href="main_classes/output.html#maskedlmoutput">MaskedLMOutput</a></li>
<li class="toctree-l2"><a class="reference internal" href="main_classes/output.html#seq2seqlmoutput">Seq2SeqLMOutput</a></li>
<li class="toctree-l2"><a class="reference internal" href="main_classes/output.html#nextsentencepredictoroutput">NextSentencePredictorOutput</a></li>
<li class="toctree-l2"><a class="reference internal" href="main_classes/output.html#sequenceclassifieroutput">SequenceClassifierOutput</a></li>
<li class="toctree-l2"><a class="reference internal" href="main_classes/output.html#seq2seqsequenceclassifieroutput">Seq2SeqSequenceClassifierOutput</a></li>
<li class="toctree-l2"><a class="reference internal" href="main_classes/output.html#multiplechoicemodeloutput">MultipleChoiceModelOutput</a></li>
<li class="toctree-l2"><a class="reference internal" href="main_classes/output.html#tokenclassifieroutput">TokenClassifierOutput</a></li>
<li class="toctree-l2"><a class="reference internal" href="main_classes/output.html#questionansweringmodeloutput">QuestionAnsweringModelOutput</a></li>
<li class="toctree-l2"><a class="reference internal" href="main_classes/output.html#seq2seqquestionansweringmodeloutput">Seq2SeqQuestionAnsweringModelOutput</a></li>
<li class="toctree-l2"><a class="reference internal" href="main_classes/output.html#tfbasemodeloutput">TFBaseModelOutput</a></li>
<li class="toctree-l2"><a class="reference internal" href="main_classes/output.html#tfbasemodeloutputwithpooling">TFBaseModelOutputWithPooling</a></li>
<li class="toctree-l2"><a class="reference internal" href="main_classes/output.html#tfbasemodeloutputwithpast">TFBaseModelOutputWithPast</a></li>
<li class="toctree-l2"><a class="reference internal" href="main_classes/output.html#tfseq2seqmodeloutput">TFSeq2SeqModelOutput</a></li>
<li class="toctree-l2"><a class="reference internal" href="main_classes/output.html#tfcausallmoutput">TFCausalLMOutput</a></li>
<li class="toctree-l2"><a class="reference internal" href="main_classes/output.html#tfcausallmoutputwithpast">TFCausalLMOutputWithPast</a></li>
<li class="toctree-l2"><a class="reference internal" href="main_classes/output.html#tfmaskedlmoutput">TFMaskedLMOutput</a></li>
<li class="toctree-l2"><a class="reference internal" href="main_classes/output.html#tfseq2seqlmoutput">TFSeq2SeqLMOutput</a></li>
<li class="toctree-l2"><a class="reference internal" href="main_classes/output.html#tfnextsentencepredictoroutput">TFNextSentencePredictorOutput</a></li>
<li class="toctree-l2"><a class="reference internal" href="main_classes/output.html#tfsequenceclassifieroutput">TFSequenceClassifierOutput</a></li>
<li class="toctree-l2"><a class="reference internal" href="main_classes/output.html#tfseq2seqsequenceclassifieroutput">TFSeq2SeqSequenceClassifierOutput</a></li>
<li class="toctree-l2"><a class="reference internal" href="main_classes/output.html#tfmultiplechoicemodeloutput">TFMultipleChoiceModelOutput</a></li>
<li class="toctree-l2"><a class="reference internal" href="main_classes/output.html#tftokenclassifieroutput">TFTokenClassifierOutput</a></li>
<li class="toctree-l2"><a class="reference internal" href="main_classes/output.html#tfquestionansweringmodeloutput">TFQuestionAnsweringModelOutput</a></li>
<li class="toctree-l2"><a class="reference internal" href="main_classes/output.html#tfseq2seqquestionansweringmodeloutput">TFSeq2SeqQuestionAnsweringModelOutput</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="main_classes/pipelines.html">Pipelines</a><ul>
<li class="toctree-l2"><a class="reference internal" href="main_classes/pipelines.html#the-pipeline-abstraction">The pipeline abstraction</a></li>
<li class="toctree-l2"><a class="reference internal" href="main_classes/pipelines.html#the-task-specific-pipelines">The task specific pipelines</a></li>
<li class="toctree-l2"><a class="reference internal" href="main_classes/pipelines.html#parent-class-pipeline">Parent class: <code class="xref py py-obj docutils literal notranslate"><span class="pre">Pipeline</span></code></a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="main_classes/processors.html">Processors</a><ul>
<li class="toctree-l2"><a class="reference internal" href="main_classes/processors.html#id1">Processors</a></li>
<li class="toctree-l2"><a class="reference internal" href="main_classes/processors.html#glue">GLUE</a></li>
<li class="toctree-l2"><a class="reference internal" href="main_classes/processors.html#xnli">XNLI</a></li>
<li class="toctree-l2"><a class="reference internal" href="main_classes/processors.html#squad">SQuAD</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="main_classes/tokenizer.html">Tokenizer</a><ul>
<li class="toctree-l2"><a class="reference internal" href="main_classes/tokenizer.html#pretrainedtokenizer">PreTrainedTokenizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="main_classes/tokenizer.html#pretrainedtokenizerfast">PreTrainedTokenizerFast</a></li>
<li class="toctree-l2"><a class="reference internal" href="main_classes/tokenizer.html#batchencoding">BatchEncoding</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="main_classes/trainer.html">Trainer</a><ul>
<li class="toctree-l2"><a class="reference internal" href="main_classes/trainer.html#id1">Trainer</a></li>
<li class="toctree-l2"><a class="reference internal" href="main_classes/trainer.html#seq2seqtrainer">Seq2SeqTrainer</a></li>
<li class="toctree-l2"><a class="reference internal" href="main_classes/trainer.html#tftrainer">TFTrainer</a></li>
<li class="toctree-l2"><a class="reference internal" href="main_classes/trainer.html#trainingarguments">TrainingArguments</a></li>
<li class="toctree-l2"><a class="reference internal" href="main_classes/trainer.html#seq2seqtrainingarguments">Seq2SeqTrainingArguments</a></li>
<li class="toctree-l2"><a class="reference internal" href="main_classes/trainer.html#tftrainingarguments">TFTrainingArguments</a></li>
<li class="toctree-l2"><a class="reference internal" href="main_classes/trainer.html#randomness">Randomness</a></li>
<li class="toctree-l2"><a class="reference internal" href="main_classes/trainer.html#trainer-integrations">Trainer Integrations</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="main_classes/feature_extractor.html">Feature Extractor</a><ul>
<li class="toctree-l2"><a class="reference internal" href="main_classes/feature_extractor.html#featureextractionmixin">FeatureExtractionMixin</a></li>
<li class="toctree-l2"><a class="reference internal" href="main_classes/feature_extractor.html#sequencefeatureextractor">SequenceFeatureExtractor</a></li>
<li class="toctree-l2"><a class="reference internal" href="main_classes/feature_extractor.html#batchfeature">BatchFeature</a></li>
<li class="toctree-l2"><a class="reference internal" href="main_classes/feature_extractor.html#imagefeatureextractionmixin">ImageFeatureExtractionMixin</a></li>
</ul>
</li>
</ul>
</div>
<div class="toctree-wrapper compound">
<p class="caption"><span class="caption-text">Models</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="model_doc/albert.html">ALBERT</a><ul>
<li class="toctree-l2"><a class="reference internal" href="model_doc/albert.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/albert.html#albertconfig">AlbertConfig</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/albert.html#alberttokenizer">AlbertTokenizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/albert.html#alberttokenizerfast">AlbertTokenizerFast</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/albert.html#albert-specific-outputs">Albert specific outputs</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/albert.html#albertmodel">AlbertModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/albert.html#albertforpretraining">AlbertForPreTraining</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/albert.html#albertformaskedlm">AlbertForMaskedLM</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/albert.html#albertforsequenceclassification">AlbertForSequenceClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/albert.html#albertformultiplechoice">AlbertForMultipleChoice</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/albert.html#albertfortokenclassification">AlbertForTokenClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/albert.html#albertforquestionanswering">AlbertForQuestionAnswering</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/albert.html#tfalbertmodel">TFAlbertModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/albert.html#tfalbertforpretraining">TFAlbertForPreTraining</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/albert.html#tfalbertformaskedlm">TFAlbertForMaskedLM</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/albert.html#tfalbertforsequenceclassification">TFAlbertForSequenceClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/albert.html#tfalbertformultiplechoice">TFAlbertForMultipleChoice</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/albert.html#tfalbertfortokenclassification">TFAlbertForTokenClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/albert.html#tfalbertforquestionanswering">TFAlbertForQuestionAnswering</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/auto.html">Auto Classes</a><ul>
<li class="toctree-l2"><a class="reference internal" href="model_doc/auto.html#autoconfig">AutoConfig</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/auto.html#autotokenizer">AutoTokenizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/auto.html#autofeatureextractor">AutoFeatureExtractor</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/auto.html#automodel">AutoModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/auto.html#automodelforpretraining">AutoModelForPreTraining</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/auto.html#automodelforcausallm">AutoModelForCausalLM</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/auto.html#automodelformaskedlm">AutoModelForMaskedLM</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/auto.html#automodelforseq2seqlm">AutoModelForSeq2SeqLM</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/auto.html#automodelforsequenceclassification">AutoModelForSequenceClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/auto.html#automodelformultiplechoice">AutoModelForMultipleChoice</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/auto.html#automodelfornextsentenceprediction">AutoModelForNextSentencePrediction</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/auto.html#automodelfortokenclassification">AutoModelForTokenClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/auto.html#automodelforquestionanswering">AutoModelForQuestionAnswering</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/auto.html#automodelfortablequestionanswering">AutoModelForTableQuestionAnswering</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/auto.html#automodelforimageclassification">AutoModelForImageClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/auto.html#tfautomodel">TFAutoModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/auto.html#tfautomodelforpretraining">TFAutoModelForPreTraining</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/auto.html#tfautomodelforcausallm">TFAutoModelForCausalLM</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/auto.html#tfautomodelformaskedlm">TFAutoModelForMaskedLM</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/auto.html#tfautomodelforseq2seqlm">TFAutoModelForSeq2SeqLM</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/auto.html#tfautomodelforsequenceclassification">TFAutoModelForSequenceClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/auto.html#tfautomodelformultiplechoice">TFAutoModelForMultipleChoice</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/auto.html#tfautomodelfortokenclassification">TFAutoModelForTokenClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/auto.html#tfautomodelforquestionanswering">TFAutoModelForQuestionAnswering</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/auto.html#flaxautomodel">FlaxAutoModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/auto.html#flaxautomodelforpretraining">FlaxAutoModelForPreTraining</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/auto.html#flaxautomodelformaskedlm">FlaxAutoModelForMaskedLM</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/auto.html#flaxautomodelforsequenceclassification">FlaxAutoModelForSequenceClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/auto.html#flaxautomodelforquestionanswering">FlaxAutoModelForQuestionAnswering</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/auto.html#flaxautomodelfortokenclassification">FlaxAutoModelForTokenClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/auto.html#flaxautomodelformultiplechoice">FlaxAutoModelForMultipleChoice</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/auto.html#flaxautomodelfornextsentenceprediction">FlaxAutoModelForNextSentencePrediction</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/bart.html">BART</a><ul>
<li class="toctree-l2"><a class="reference internal" href="model_doc/bart.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/bart.html#implementation-notes">Implementation Notes</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/bart.html#mask-filling">Mask Filling</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/bart.html#bartconfig">BartConfig</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/bart.html#barttokenizer">BartTokenizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/bart.html#barttokenizerfast">BartTokenizerFast</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/bart.html#bartmodel">BartModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/bart.html#bartforconditionalgeneration">BartForConditionalGeneration</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/bart.html#bartforsequenceclassification">BartForSequenceClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/bart.html#bartforquestionanswering">BartForQuestionAnswering</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/bart.html#bartforcausallm">BartForCausalLM</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/bart.html#tfbartmodel">TFBartModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/bart.html#tfbartforconditionalgeneration">TFBartForConditionalGeneration</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/barthez.html">BARThez</a><ul>
<li class="toctree-l2"><a class="reference internal" href="model_doc/barthez.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/barthez.html#bartheztokenizer">BarthezTokenizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/barthez.html#bartheztokenizerfast">BarthezTokenizerFast</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/bert.html">BERT</a><ul>
<li class="toctree-l2"><a class="reference internal" href="model_doc/bert.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/bert.html#bertconfig">BertConfig</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/bert.html#berttokenizer">BertTokenizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/bert.html#berttokenizerfast">BertTokenizerFast</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/bert.html#bert-specific-outputs">Bert specific outputs</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/bert.html#bertmodel">BertModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/bert.html#bertforpretraining">BertForPreTraining</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/bert.html#bertlmheadmodel">BertLMHeadModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/bert.html#bertformaskedlm">BertForMaskedLM</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/bert.html#bertfornextsentenceprediction">BertForNextSentencePrediction</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/bert.html#bertforsequenceclassification">BertForSequenceClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/bert.html#bertformultiplechoice">BertForMultipleChoice</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/bert.html#bertfortokenclassification">BertForTokenClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/bert.html#bertforquestionanswering">BertForQuestionAnswering</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/bert.html#tfbertmodel">TFBertModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/bert.html#tfbertforpretraining">TFBertForPreTraining</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/bert.html#tfbertmodellmheadmodel">TFBertModelLMHeadModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/bert.html#tfbertformaskedlm">TFBertForMaskedLM</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/bert.html#tfbertfornextsentenceprediction">TFBertForNextSentencePrediction</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/bert.html#tfbertforsequenceclassification">TFBertForSequenceClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/bert.html#tfbertformultiplechoice">TFBertForMultipleChoice</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/bert.html#tfbertfortokenclassification">TFBertForTokenClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/bert.html#tfbertforquestionanswering">TFBertForQuestionAnswering</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/bert.html#flaxbertmodel">FlaxBertModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/bert.html#flaxbertforpretraining">FlaxBertForPreTraining</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/bert.html#flaxbertformaskedlm">FlaxBertForMaskedLM</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/bert.html#flaxbertfornextsentenceprediction">FlaxBertForNextSentencePrediction</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/bert.html#flaxbertforsequenceclassification">FlaxBertForSequenceClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/bert.html#flaxbertformultiplechoice">FlaxBertForMultipleChoice</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/bert.html#flaxbertfortokenclassification">FlaxBertForTokenClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/bert.html#flaxbertforquestionanswering">FlaxBertForQuestionAnswering</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/bertweet.html">Bertweet</a><ul>
<li class="toctree-l2"><a class="reference internal" href="model_doc/bertweet.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/bertweet.html#bertweettokenizer">BertweetTokenizer</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/bertgeneration.html">BertGeneration</a><ul>
<li class="toctree-l2"><a class="reference internal" href="model_doc/bertgeneration.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/bertgeneration.html#bertgenerationconfig">BertGenerationConfig</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/bertgeneration.html#bertgenerationtokenizer">BertGenerationTokenizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/bertgeneration.html#bertgenerationencoder">BertGenerationEncoder</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/bertgeneration.html#bertgenerationdecoder">BertGenerationDecoder</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/bert_japanese.html">BertJapanese</a><ul>
<li class="toctree-l2"><a class="reference internal" href="model_doc/bert_japanese.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/bert_japanese.html#bertjapanesetokenizer">BertJapaneseTokenizer</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/bigbird.html">BigBird</a><ul>
<li class="toctree-l2"><a class="reference internal" href="model_doc/bigbird.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/bigbird.html#bigbirdconfig">BigBirdConfig</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/bigbird.html#bigbirdtokenizer">BigBirdTokenizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/bigbird.html#bigbirdtokenizerfast">BigBirdTokenizerFast</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/bigbird.html#bigbird-specific-outputs">BigBird specific outputs</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/bigbird.html#bigbirdmodel">BigBirdModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/bigbird.html#bigbirdforpretraining">BigBirdForPreTraining</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/bigbird.html#bigbirdforcausallm">BigBirdForCausalLM</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/bigbird.html#bigbirdformaskedlm">BigBirdForMaskedLM</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/bigbird.html#bigbirdforsequenceclassification">BigBirdForSequenceClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/bigbird.html#bigbirdformultiplechoice">BigBirdForMultipleChoice</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/bigbird.html#bigbirdfortokenclassification">BigBirdForTokenClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/bigbird.html#bigbirdforquestionanswering">BigBirdForQuestionAnswering</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/bigbird_pegasus.html">BigBirdPegasus</a><ul>
<li class="toctree-l2"><a class="reference internal" href="model_doc/bigbird_pegasus.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/bigbird_pegasus.html#bigbirdpegasusconfig">BigBirdPegasusConfig</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/bigbird_pegasus.html#bigbirdpegasusmodel">BigBirdPegasusModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/bigbird_pegasus.html#bigbirdpegasusforconditionalgeneration">BigBirdPegasusForConditionalGeneration</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/bigbird_pegasus.html#bigbirdpegasusforsequenceclassification">BigBirdPegasusForSequenceClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/bigbird_pegasus.html#bigbirdpegasusforquestionanswering">BigBirdPegasusForQuestionAnswering</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/bigbird_pegasus.html#bigbirdpegasusforcausallm">BigBirdPegasusForCausalLM</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/blenderbot.html">Blenderbot</a><ul>
<li class="toctree-l2"><a class="reference internal" href="model_doc/blenderbot.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/blenderbot.html#implementation-notes">Implementation Notes</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/blenderbot.html#usage">Usage</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/blenderbot.html#blenderbotconfig">BlenderbotConfig</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/blenderbot.html#blenderbottokenizer">BlenderbotTokenizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/blenderbot.html#blenderbotmodel">BlenderbotModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/blenderbot.html#blenderbotforconditionalgeneration">BlenderbotForConditionalGeneration</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/blenderbot.html#blenderbotforcausallm">BlenderbotForCausalLM</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/blenderbot.html#tfblenderbotmodel">TFBlenderbotModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/blenderbot.html#tfblenderbotforconditionalgeneration">TFBlenderbotForConditionalGeneration</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/blenderbot_small.html">Blenderbot Small</a><ul>
<li class="toctree-l2"><a class="reference internal" href="model_doc/blenderbot_small.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/blenderbot_small.html#blenderbotsmallconfig">BlenderbotSmallConfig</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/blenderbot_small.html#blenderbotsmalltokenizer">BlenderbotSmallTokenizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/blenderbot_small.html#blenderbotsmallmodel">BlenderbotSmallModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/blenderbot_small.html#blenderbotsmallforconditionalgeneration">BlenderbotSmallForConditionalGeneration</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/blenderbot_small.html#blenderbotsmallforcausallm">BlenderbotSmallForCausalLM</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/blenderbot_small.html#tfblenderbotsmallmodel">TFBlenderbotSmallModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/blenderbot_small.html#tfblenderbotsmallforconditionalgeneration">TFBlenderbotSmallForConditionalGeneration</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/bort.html">BORT</a><ul>
<li class="toctree-l2"><a class="reference internal" href="model_doc/bort.html#overview">Overview</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/camembert.html">CamemBERT</a><ul>
<li class="toctree-l2"><a class="reference internal" href="model_doc/camembert.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/camembert.html#camembertconfig">CamembertConfig</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/camembert.html#camemberttokenizer">CamembertTokenizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/camembert.html#camemberttokenizerfast">CamembertTokenizerFast</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/camembert.html#camembertmodel">CamembertModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/camembert.html#camembertforcausallm">CamembertForCausalLM</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/camembert.html#camembertformaskedlm">CamembertForMaskedLM</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/camembert.html#camembertforsequenceclassification">CamembertForSequenceClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/camembert.html#camembertformultiplechoice">CamembertForMultipleChoice</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/camembert.html#camembertfortokenclassification">CamembertForTokenClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/camembert.html#camembertforquestionanswering">CamembertForQuestionAnswering</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/camembert.html#tfcamembertmodel">TFCamembertModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/camembert.html#tfcamembertformaskedlm">TFCamembertForMaskedLM</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/camembert.html#tfcamembertforsequenceclassification">TFCamembertForSequenceClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/camembert.html#tfcamembertformultiplechoice">TFCamembertForMultipleChoice</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/camembert.html#tfcamembertfortokenclassification">TFCamembertForTokenClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/camembert.html#tfcamembertforquestionanswering">TFCamembertForQuestionAnswering</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/clip.html">CLIP</a><ul>
<li class="toctree-l2"><a class="reference internal" href="model_doc/clip.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/clip.html#usage">Usage</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/clip.html#clipconfig">CLIPConfig</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/clip.html#cliptextconfig">CLIPTextConfig</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/clip.html#clipvisionconfig">CLIPVisionConfig</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/clip.html#cliptokenizer">CLIPTokenizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/clip.html#cliptokenizerfast">CLIPTokenizerFast</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/clip.html#clipfeatureextractor">CLIPFeatureExtractor</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/clip.html#clipprocessor">CLIPProcessor</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/clip.html#clipmodel">CLIPModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/clip.html#cliptextmodel">CLIPTextModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/clip.html#clipvisionmodel">CLIPVisionModel</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/convbert.html">ConvBERT</a><ul>
<li class="toctree-l2"><a class="reference internal" href="model_doc/convbert.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/convbert.html#convbertconfig">ConvBertConfig</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/convbert.html#convberttokenizer">ConvBertTokenizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/convbert.html#convberttokenizerfast">ConvBertTokenizerFast</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/convbert.html#convbertmodel">ConvBertModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/convbert.html#convbertformaskedlm">ConvBertForMaskedLM</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/convbert.html#convbertforsequenceclassification">ConvBertForSequenceClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/convbert.html#convbertformultiplechoice">ConvBertForMultipleChoice</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/convbert.html#convbertfortokenclassification">ConvBertForTokenClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/convbert.html#convbertforquestionanswering">ConvBertForQuestionAnswering</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/convbert.html#tfconvbertmodel">TFConvBertModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/convbert.html#tfconvbertformaskedlm">TFConvBertForMaskedLM</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/convbert.html#tfconvbertforsequenceclassification">TFConvBertForSequenceClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/convbert.html#tfconvbertformultiplechoice">TFConvBertForMultipleChoice</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/convbert.html#tfconvbertfortokenclassification">TFConvBertForTokenClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/convbert.html#tfconvbertforquestionanswering">TFConvBertForQuestionAnswering</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/cpm.html">CPM</a><ul>
<li class="toctree-l2"><a class="reference internal" href="model_doc/cpm.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/cpm.html#cpmtokenizer">CpmTokenizer</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/ctrl.html">CTRL</a><ul>
<li class="toctree-l2"><a class="reference internal" href="model_doc/ctrl.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/ctrl.html#ctrlconfig">CTRLConfig</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/ctrl.html#ctrltokenizer">CTRLTokenizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/ctrl.html#ctrlmodel">CTRLModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/ctrl.html#ctrllmheadmodel">CTRLLMHeadModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/ctrl.html#ctrlforsequenceclassification">CTRLForSequenceClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/ctrl.html#tfctrlmodel">TFCTRLModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/ctrl.html#tfctrllmheadmodel">TFCTRLLMHeadModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/ctrl.html#tfctrlforsequenceclassification">TFCTRLForSequenceClassification</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/deberta.html">DeBERTa</a><ul>
<li class="toctree-l2"><a class="reference internal" href="model_doc/deberta.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/deberta.html#debertaconfig">DebertaConfig</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/deberta.html#debertatokenizer">DebertaTokenizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/deberta.html#debertatokenizerfast">DebertaTokenizerFast</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/deberta.html#debertamodel">DebertaModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/deberta.html#debertapretrainedmodel">DebertaPreTrainedModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/deberta.html#debertaformaskedlm">DebertaForMaskedLM</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/deberta.html#debertaforsequenceclassification">DebertaForSequenceClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/deberta.html#debertafortokenclassification">DebertaForTokenClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/deberta.html#debertaforquestionanswering">DebertaForQuestionAnswering</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/deberta_v2.html">DeBERTa-v2</a><ul>
<li class="toctree-l2"><a class="reference internal" href="model_doc/deberta_v2.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/deberta_v2.html#debertav2config">DebertaV2Config</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/deberta_v2.html#debertav2tokenizer">DebertaV2Tokenizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/deberta_v2.html#debertav2model">DebertaV2Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/deberta_v2.html#debertav2pretrainedmodel">DebertaV2PreTrainedModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/deberta_v2.html#debertav2formaskedlm">DebertaV2ForMaskedLM</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/deberta_v2.html#debertav2forsequenceclassification">DebertaV2ForSequenceClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/deberta_v2.html#debertav2fortokenclassification">DebertaV2ForTokenClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/deberta_v2.html#debertav2forquestionanswering">DebertaV2ForQuestionAnswering</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/deit.html">DeiT</a><ul>
<li class="toctree-l2"><a class="reference internal" href="model_doc/deit.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/deit.html#deitconfig">DeiTConfig</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/deit.html#deitfeatureextractor">DeiTFeatureExtractor</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/deit.html#deitmodel">DeiTModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/deit.html#deitforimageclassification">DeiTForImageClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/deit.html#deitforimageclassificationwithteacher">DeiTForImageClassificationWithTeacher</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/dialogpt.html">DialoGPT</a><ul>
<li class="toctree-l2"><a class="reference internal" href="model_doc/dialogpt.html#overview">Overview</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/distilbert.html">DistilBERT</a><ul>
<li class="toctree-l2"><a class="reference internal" href="model_doc/distilbert.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/distilbert.html#distilbertconfig">DistilBertConfig</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/distilbert.html#distilberttokenizer">DistilBertTokenizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/distilbert.html#distilberttokenizerfast">DistilBertTokenizerFast</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/distilbert.html#distilbertmodel">DistilBertModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/distilbert.html#distilbertformaskedlm">DistilBertForMaskedLM</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/distilbert.html#distilbertforsequenceclassification">DistilBertForSequenceClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/distilbert.html#distilbertformultiplechoice">DistilBertForMultipleChoice</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/distilbert.html#distilbertfortokenclassification">DistilBertForTokenClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/distilbert.html#distilbertforquestionanswering">DistilBertForQuestionAnswering</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/distilbert.html#tfdistilbertmodel">TFDistilBertModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/distilbert.html#tfdistilbertformaskedlm">TFDistilBertForMaskedLM</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/distilbert.html#tfdistilbertforsequenceclassification">TFDistilBertForSequenceClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/distilbert.html#tfdistilbertformultiplechoice">TFDistilBertForMultipleChoice</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/distilbert.html#tfdistilbertfortokenclassification">TFDistilBertForTokenClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/distilbert.html#tfdistilbertforquestionanswering">TFDistilBertForQuestionAnswering</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/dpr.html">DPR</a><ul>
<li class="toctree-l2"><a class="reference internal" href="model_doc/dpr.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/dpr.html#dprconfig">DPRConfig</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/dpr.html#dprcontextencodertokenizer">DPRContextEncoderTokenizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/dpr.html#dprcontextencodertokenizerfast">DPRContextEncoderTokenizerFast</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/dpr.html#dprquestionencodertokenizer">DPRQuestionEncoderTokenizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/dpr.html#dprquestionencodertokenizerfast">DPRQuestionEncoderTokenizerFast</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/dpr.html#dprreadertokenizer">DPRReaderTokenizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/dpr.html#dprreadertokenizerfast">DPRReaderTokenizerFast</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/dpr.html#dpr-specific-outputs">DPR specific outputs</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/dpr.html#dprcontextencoder">DPRContextEncoder</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/dpr.html#dprquestionencoder">DPRQuestionEncoder</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/dpr.html#dprreader">DPRReader</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/dpr.html#tfdprcontextencoder">TFDPRContextEncoder</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/dpr.html#tfdprquestionencoder">TFDPRQuestionEncoder</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/dpr.html#tfdprreader">TFDPRReader</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/electra.html">ELECTRA</a><ul>
<li class="toctree-l2"><a class="reference internal" href="model_doc/electra.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/electra.html#electraconfig">ElectraConfig</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/electra.html#electratokenizer">ElectraTokenizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/electra.html#electratokenizerfast">ElectraTokenizerFast</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/electra.html#electra-specific-outputs">Electra specific outputs</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/electra.html#electramodel">ElectraModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/electra.html#electraforpretraining">ElectraForPreTraining</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/electra.html#electraformaskedlm">ElectraForMaskedLM</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/electra.html#electraforsequenceclassification">ElectraForSequenceClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/electra.html#electraformultiplechoice">ElectraForMultipleChoice</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/electra.html#electrafortokenclassification">ElectraForTokenClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/electra.html#electraforquestionanswering">ElectraForQuestionAnswering</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/electra.html#tfelectramodel">TFElectraModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/electra.html#tfelectraforpretraining">TFElectraForPreTraining</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/electra.html#tfelectraformaskedlm">TFElectraForMaskedLM</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/electra.html#tfelectraforsequenceclassification">TFElectraForSequenceClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/electra.html#tfelectraformultiplechoice">TFElectraForMultipleChoice</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/electra.html#tfelectrafortokenclassification">TFElectraForTokenClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/electra.html#tfelectraforquestionanswering">TFElectraForQuestionAnswering</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/electra.html#flaxelectramodel">FlaxElectraModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/electra.html#flaxelectraforpretraining">FlaxElectraForPreTraining</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/electra.html#flaxelectraformaskedlm">FlaxElectraForMaskedLM</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/electra.html#flaxelectraforsequenceclassification">FlaxElectraForSequenceClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/electra.html#flaxelectraformultiplechoice">FlaxElectraForMultipleChoice</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/electra.html#flaxelectrafortokenclassification">FlaxElectraForTokenClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/electra.html#flaxelectraforquestionanswering">FlaxElectraForQuestionAnswering</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/encoderdecoder.html">Encoder Decoder Models</a><ul>
<li class="toctree-l2"><a class="reference internal" href="model_doc/encoderdecoder.html#encoderdecoderconfig">EncoderDecoderConfig</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/encoderdecoder.html#encoderdecodermodel">EncoderDecoderModel</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/flaubert.html">FlauBERT</a><ul>
<li class="toctree-l2"><a class="reference internal" href="model_doc/flaubert.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/flaubert.html#flaubertconfig">FlaubertConfig</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/flaubert.html#flauberttokenizer">FlaubertTokenizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/flaubert.html#flaubertmodel">FlaubertModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/flaubert.html#flaubertwithlmheadmodel">FlaubertWithLMHeadModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/flaubert.html#flaubertforsequenceclassification">FlaubertForSequenceClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/flaubert.html#flaubertformultiplechoice">FlaubertForMultipleChoice</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/flaubert.html#flaubertfortokenclassification">FlaubertForTokenClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/flaubert.html#flaubertforquestionansweringsimple">FlaubertForQuestionAnsweringSimple</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/flaubert.html#flaubertforquestionanswering">FlaubertForQuestionAnswering</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/flaubert.html#tfflaubertmodel">TFFlaubertModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/flaubert.html#tfflaubertwithlmheadmodel">TFFlaubertWithLMHeadModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/flaubert.html#tfflaubertforsequenceclassification">TFFlaubertForSequenceClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/flaubert.html#tfflaubertformultiplechoice">TFFlaubertForMultipleChoice</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/flaubert.html#tfflaubertfortokenclassification">TFFlaubertForTokenClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/flaubert.html#tfflaubertforquestionansweringsimple">TFFlaubertForQuestionAnsweringSimple</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/fsmt.html">FSMT</a><ul>
<li class="toctree-l2"><a class="reference internal" href="model_doc/fsmt.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/fsmt.html#implementation-notes">Implementation Notes</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/fsmt.html#fsmtconfig">FSMTConfig</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/fsmt.html#fsmttokenizer">FSMTTokenizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/fsmt.html#fsmtmodel">FSMTModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/fsmt.html#fsmtforconditionalgeneration">FSMTForConditionalGeneration</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/funnel.html">Funnel Transformer</a><ul>
<li class="toctree-l2"><a class="reference internal" href="model_doc/funnel.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/funnel.html#funnelconfig">FunnelConfig</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/funnel.html#funneltokenizer">FunnelTokenizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/funnel.html#funneltokenizerfast">FunnelTokenizerFast</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/funnel.html#funnel-specific-outputs">Funnel specific outputs</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/funnel.html#funnelbasemodel">FunnelBaseModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/funnel.html#funnelmodel">FunnelModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/funnel.html#funnelmodelforpretraining">FunnelModelForPreTraining</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/funnel.html#funnelformaskedlm">FunnelForMaskedLM</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/funnel.html#funnelforsequenceclassification">FunnelForSequenceClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/funnel.html#funnelformultiplechoice">FunnelForMultipleChoice</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/funnel.html#funnelfortokenclassification">FunnelForTokenClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/funnel.html#funnelforquestionanswering">FunnelForQuestionAnswering</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/funnel.html#tffunnelbasemodel">TFFunnelBaseModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/funnel.html#tffunnelmodel">TFFunnelModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/funnel.html#tffunnelmodelforpretraining">TFFunnelModelForPreTraining</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/funnel.html#tffunnelformaskedlm">TFFunnelForMaskedLM</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/funnel.html#tffunnelforsequenceclassification">TFFunnelForSequenceClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/funnel.html#tffunnelformultiplechoice">TFFunnelForMultipleChoice</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/funnel.html#tffunnelfortokenclassification">TFFunnelForTokenClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/funnel.html#tffunnelforquestionanswering">TFFunnelForQuestionAnswering</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/herbert.html">herBERT</a><ul>
<li class="toctree-l2"><a class="reference internal" href="model_doc/herbert.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/herbert.html#herberttokenizer">HerbertTokenizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/herbert.html#herberttokenizerfast">HerbertTokenizerFast</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/ibert.html">I-BERT</a><ul>
<li class="toctree-l2"><a class="reference internal" href="model_doc/ibert.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/ibert.html#ibertconfig">IBertConfig</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/ibert.html#ibertmodel">IBertModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/ibert.html#ibertformaskedlm">IBertForMaskedLM</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/ibert.html#ibertforsequenceclassification">IBertForSequenceClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/ibert.html#ibertformultiplechoice">IBertForMultipleChoice</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/ibert.html#ibertfortokenclassification">IBertForTokenClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/ibert.html#ibertforquestionanswering">IBertForQuestionAnswering</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/layoutlm.html">LayoutLM</a><ul>
<li class="toctree-l2"><a class="reference internal" href="model_doc/layoutlm.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/layoutlm.html#layoutlmconfig">LayoutLMConfig</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/layoutlm.html#layoutlmtokenizer">LayoutLMTokenizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/layoutlm.html#layoutlmtokenizerfast">LayoutLMTokenizerFast</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/layoutlm.html#layoutlmmodel">LayoutLMModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/layoutlm.html#layoutlmformaskedlm">LayoutLMForMaskedLM</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/layoutlm.html#layoutlmforsequenceclassification">LayoutLMForSequenceClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/layoutlm.html#layoutlmfortokenclassification">LayoutLMForTokenClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/layoutlm.html#tflayoutlmmodel">TFLayoutLMModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/layoutlm.html#tflayoutlmformaskedlm">TFLayoutLMForMaskedLM</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/layoutlm.html#tflayoutlmforsequenceclassification">TFLayoutLMForSequenceClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/layoutlm.html#tflayoutlmfortokenclassification">TFLayoutLMForTokenClassification</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/led.html">LED</a><ul>
<li class="toctree-l2"><a class="reference internal" href="model_doc/led.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/led.html#ledconfig">LEDConfig</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/led.html#ledtokenizer">LEDTokenizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/led.html#ledtokenizerfast">LEDTokenizerFast</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/led.html#led-specific-outputs">LED specific outputs</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/led.html#ledmodel">LEDModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/led.html#ledforconditionalgeneration">LEDForConditionalGeneration</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/led.html#ledforsequenceclassification">LEDForSequenceClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/led.html#ledforquestionanswering">LEDForQuestionAnswering</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/led.html#tfledmodel">TFLEDModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/led.html#tfledforconditionalgeneration">TFLEDForConditionalGeneration</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/longformer.html">Longformer</a><ul>
<li class="toctree-l2"><a class="reference internal" href="model_doc/longformer.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/longformer.html#longformer-self-attention">Longformer Self Attention</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/longformer.html#training">Training</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/longformer.html#longformerconfig">LongformerConfig</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/longformer.html#longformertokenizer">LongformerTokenizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/longformer.html#longformertokenizerfast">LongformerTokenizerFast</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/longformer.html#longformer-specific-outputs">Longformer specific outputs</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/longformer.html#longformermodel">LongformerModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/longformer.html#longformerformaskedlm">LongformerForMaskedLM</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/longformer.html#longformerforsequenceclassification">LongformerForSequenceClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/longformer.html#longformerformultiplechoice">LongformerForMultipleChoice</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/longformer.html#longformerfortokenclassification">LongformerForTokenClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/longformer.html#longformerforquestionanswering">LongformerForQuestionAnswering</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/longformer.html#tflongformermodel">TFLongformerModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/longformer.html#tflongformerformaskedlm">TFLongformerForMaskedLM</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/longformer.html#tflongformerforquestionanswering">TFLongformerForQuestionAnswering</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/longformer.html#tflongformerforsequenceclassification">TFLongformerForSequenceClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/longformer.html#tflongformerfortokenclassification">TFLongformerForTokenClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/longformer.html#tflongformerformultiplechoice">TFLongformerForMultipleChoice</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/luke.html">LUKE</a><ul>
<li class="toctree-l2"><a class="reference internal" href="model_doc/luke.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/luke.html#lukeconfig">LukeConfig</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/luke.html#luketokenizer">LukeTokenizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/luke.html#lukemodel">LukeModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/luke.html#lukeforentityclassification">LukeForEntityClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/luke.html#lukeforentitypairclassification">LukeForEntityPairClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/luke.html#lukeforentityspanclassification">LukeForEntitySpanClassification</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/lxmert.html">LXMERT</a><ul>
<li class="toctree-l2"><a class="reference internal" href="model_doc/lxmert.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/lxmert.html#lxmertconfig">LxmertConfig</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/lxmert.html#lxmerttokenizer">LxmertTokenizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/lxmert.html#lxmerttokenizerfast">LxmertTokenizerFast</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/lxmert.html#lxmert-specific-outputs">Lxmert specific outputs</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/lxmert.html#lxmertmodel">LxmertModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/lxmert.html#lxmertforpretraining">LxmertForPreTraining</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/lxmert.html#lxmertforquestionanswering">LxmertForQuestionAnswering</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/lxmert.html#tflxmertmodel">TFLxmertModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/lxmert.html#tflxmertforpretraining">TFLxmertForPreTraining</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/marian.html">MarianMT</a><ul>
<li class="toctree-l2"><a class="reference internal" href="model_doc/marian.html#implementation-notes">Implementation Notes</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/marian.html#naming">Naming</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/marian.html#examples">Examples</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/marian.html#multilingual-models">Multilingual Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/marian.html#old-style-multi-lingual-models">Old Style Multi-Lingual Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/marian.html#marianconfig">MarianConfig</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/marian.html#mariantokenizer">MarianTokenizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/marian.html#marianmodel">MarianModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/marian.html#marianmtmodel">MarianMTModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/marian.html#marianforcausallm">MarianForCausalLM</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/marian.html#tfmarianmodel">TFMarianModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/marian.html#tfmarianmtmodel">TFMarianMTModel</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/m2m_100.html">M2M100</a><ul>
<li class="toctree-l2"><a class="reference internal" href="model_doc/m2m_100.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/m2m_100.html#m2m100config">M2M100Config</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/m2m_100.html#m2m100tokenizer">M2M100Tokenizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/m2m_100.html#m2m100model">M2M100Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/m2m_100.html#m2m100forconditionalgeneration">M2M100ForConditionalGeneration</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/mbart.html">MBart and MBart-50</a><ul>
<li class="toctree-l2"><a class="reference internal" href="model_doc/mbart.html#overview-of-mbart">Overview of MBart</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/mbart.html#overview-of-mbart-50">Overview of MBart-50</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/mbart.html#mbartconfig">MBartConfig</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/mbart.html#mbarttokenizer">MBartTokenizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/mbart.html#mbarttokenizerfast">MBartTokenizerFast</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/mbart.html#mbart50tokenizer">MBart50Tokenizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/mbart.html#mbart50tokenizerfast">MBart50TokenizerFast</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/mbart.html#mbartmodel">MBartModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/mbart.html#mbartforconditionalgeneration">MBartForConditionalGeneration</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/mbart.html#mbartforquestionanswering">MBartForQuestionAnswering</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/mbart.html#mbartforsequenceclassification">MBartForSequenceClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/mbart.html#mbartforcausallm">MBartForCausalLM</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/mbart.html#tfmbartmodel">TFMBartModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/mbart.html#tfmbartforconditionalgeneration">TFMBartForConditionalGeneration</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/megatron_bert.html">MegatronBERT</a><ul>
<li class="toctree-l2"><a class="reference internal" href="model_doc/megatron_bert.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/megatron_bert.html#megatronbertconfig">MegatronBertConfig</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/megatron_bert.html#megatronbertmodel">MegatronBertModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/megatron_bert.html#megatronbertformaskedlm">MegatronBertForMaskedLM</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/megatron_bert.html#megatronbertforcausallm">MegatronBertForCausalLM</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/megatron_bert.html#megatronbertfornextsentenceprediction">MegatronBertForNextSentencePrediction</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/megatron_bert.html#megatronbertforpretraining">MegatronBertForPreTraining</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/megatron_bert.html#megatronbertforsequenceclassification">MegatronBertForSequenceClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/megatron_bert.html#megatronbertformultiplechoice">MegatronBertForMultipleChoice</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/megatron_bert.html#megatronbertfortokenclassification">MegatronBertForTokenClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/megatron_bert.html#megatronbertforquestionanswering">MegatronBertForQuestionAnswering</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/megatron_gpt2.html">MegatronGPT2</a><ul>
<li class="toctree-l2"><a class="reference internal" href="model_doc/megatron_gpt2.html#overview">Overview</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/mobilebert.html">MobileBERT</a><ul>
<li class="toctree-l2"><a class="reference internal" href="model_doc/mobilebert.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/mobilebert.html#mobilebertconfig">MobileBertConfig</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/mobilebert.html#mobileberttokenizer">MobileBertTokenizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/mobilebert.html#mobileberttokenizerfast">MobileBertTokenizerFast</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/mobilebert.html#mobilebert-specific-outputs">MobileBert specific outputs</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/mobilebert.html#mobilebertmodel">MobileBertModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/mobilebert.html#mobilebertforpretraining">MobileBertForPreTraining</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/mobilebert.html#mobilebertformaskedlm">MobileBertForMaskedLM</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/mobilebert.html#mobilebertfornextsentenceprediction">MobileBertForNextSentencePrediction</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/mobilebert.html#mobilebertforsequenceclassification">MobileBertForSequenceClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/mobilebert.html#mobilebertformultiplechoice">MobileBertForMultipleChoice</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/mobilebert.html#mobilebertfortokenclassification">MobileBertForTokenClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/mobilebert.html#mobilebertforquestionanswering">MobileBertForQuestionAnswering</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/mobilebert.html#tfmobilebertmodel">TFMobileBertModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/mobilebert.html#tfmobilebertforpretraining">TFMobileBertForPreTraining</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/mobilebert.html#tfmobilebertformaskedlm">TFMobileBertForMaskedLM</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/mobilebert.html#tfmobilebertfornextsentenceprediction">TFMobileBertForNextSentencePrediction</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/mobilebert.html#tfmobilebertforsequenceclassification">TFMobileBertForSequenceClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/mobilebert.html#tfmobilebertformultiplechoice">TFMobileBertForMultipleChoice</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/mobilebert.html#tfmobilebertfortokenclassification">TFMobileBertForTokenClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/mobilebert.html#tfmobilebertforquestionanswering">TFMobileBertForQuestionAnswering</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/mpnet.html">MPNet</a><ul>
<li class="toctree-l2"><a class="reference internal" href="model_doc/mpnet.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/mpnet.html#mpnetconfig">MPNetConfig</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/mpnet.html#mpnettokenizer">MPNetTokenizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/mpnet.html#mpnettokenizerfast">MPNetTokenizerFast</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/mpnet.html#mpnetmodel">MPNetModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/mpnet.html#mpnetformaskedlm">MPNetForMaskedLM</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/mpnet.html#mpnetforsequenceclassification">MPNetForSequenceClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/mpnet.html#mpnetformultiplechoice">MPNetForMultipleChoice</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/mpnet.html#mpnetfortokenclassification">MPNetForTokenClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/mpnet.html#mpnetforquestionanswering">MPNetForQuestionAnswering</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/mpnet.html#tfmpnetmodel">TFMPNetModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/mpnet.html#tfmpnetformaskedlm">TFMPNetForMaskedLM</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/mpnet.html#tfmpnetforsequenceclassification">TFMPNetForSequenceClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/mpnet.html#tfmpnetformultiplechoice">TFMPNetForMultipleChoice</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/mpnet.html#tfmpnetfortokenclassification">TFMPNetForTokenClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/mpnet.html#tfmpnetforquestionanswering">TFMPNetForQuestionAnswering</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/mt5.html">MT5</a><ul>
<li class="toctree-l2"><a class="reference internal" href="model_doc/mt5.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/mt5.html#mt5config">MT5Config</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/mt5.html#mt5tokenizer">MT5Tokenizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/mt5.html#mt5tokenizerfast">MT5TokenizerFast</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/mt5.html#mt5model">MT5Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/mt5.html#mt5forconditionalgeneration">MT5ForConditionalGeneration</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/mt5.html#mt5encodermodel">MT5EncoderModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/mt5.html#tfmt5model">TFMT5Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/mt5.html#tfmt5forconditionalgeneration">TFMT5ForConditionalGeneration</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/mt5.html#tfmt5encodermodel">TFMT5EncoderModel</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/gpt.html">OpenAI GPT</a><ul>
<li class="toctree-l2"><a class="reference internal" href="model_doc/gpt.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/gpt.html#openaigptconfig">OpenAIGPTConfig</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/gpt.html#openaigpttokenizer">OpenAIGPTTokenizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/gpt.html#openaigpttokenizerfast">OpenAIGPTTokenizerFast</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/gpt.html#openai-specific-outputs">OpenAI specific outputs</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/gpt.html#openaigptmodel">OpenAIGPTModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/gpt.html#openaigptlmheadmodel">OpenAIGPTLMHeadModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/gpt.html#openaigptdoubleheadsmodel">OpenAIGPTDoubleHeadsModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/gpt.html#openaigptforsequenceclassification">OpenAIGPTForSequenceClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/gpt.html#tfopenaigptmodel">TFOpenAIGPTModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/gpt.html#tfopenaigptlmheadmodel">TFOpenAIGPTLMHeadModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/gpt.html#tfopenaigptdoubleheadsmodel">TFOpenAIGPTDoubleHeadsModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/gpt.html#tfopenaigptforsequenceclassification">TFOpenAIGPTForSequenceClassification</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/gpt2.html">OpenAI GPT2</a><ul>
<li class="toctree-l2"><a class="reference internal" href="model_doc/gpt2.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/gpt2.html#gpt2config">GPT2Config</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/gpt2.html#gpt2tokenizer">GPT2Tokenizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/gpt2.html#gpt2tokenizerfast">GPT2TokenizerFast</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/gpt2.html#gpt2-specific-outputs">GPT2 specific outputs</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/gpt2.html#gpt2model">GPT2Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/gpt2.html#gpt2lmheadmodel">GPT2LMHeadModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/gpt2.html#gpt2doubleheadsmodel">GPT2DoubleHeadsModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/gpt2.html#gpt2forsequenceclassification">GPT2ForSequenceClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/gpt2.html#tfgpt2model">TFGPT2Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/gpt2.html#tfgpt2lmheadmodel">TFGPT2LMHeadModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/gpt2.html#tfgpt2doubleheadsmodel">TFGPT2DoubleHeadsModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/gpt2.html#tfgpt2forsequenceclassification">TFGPT2ForSequenceClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/gpt2.html#tfsequenceclassifieroutputwithpast">TFSequenceClassifierOutputWithPast</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/gpt_neo.html">GPT Neo</a><ul>
<li class="toctree-l2"><a class="reference internal" href="model_doc/gpt_neo.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/gpt_neo.html#gptneoconfig">GPTNeoConfig</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/gpt_neo.html#gptneomodel">GPTNeoModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/gpt_neo.html#gptneoforcausallm">GPTNeoForCausalLM</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/pegasus.html">Pegasus</a><ul>
<li class="toctree-l2"><a class="reference internal" href="model_doc/pegasus.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/pegasus.html#checkpoints">Checkpoints</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/pegasus.html#implementation-notes">Implementation Notes</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/pegasus.html#usage-example">Usage Example</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/pegasus.html#pegasusconfig">PegasusConfig</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/pegasus.html#pegasustokenizer">PegasusTokenizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/pegasus.html#pegasustokenizerfast">PegasusTokenizerFast</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/pegasus.html#pegasusmodel">PegasusModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/pegasus.html#pegasusforconditionalgeneration">PegasusForConditionalGeneration</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/pegasus.html#pegasusforcausallm">PegasusForCausalLM</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/pegasus.html#tfpegasusmodel">TFPegasusModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/pegasus.html#tfpegasusforconditionalgeneration">TFPegasusForConditionalGeneration</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/phobert.html">PhoBERT</a><ul>
<li class="toctree-l2"><a class="reference internal" href="model_doc/phobert.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/phobert.html#phoberttokenizer">PhobertTokenizer</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/prophetnet.html">ProphetNet</a><ul>
<li class="toctree-l2"><a class="reference internal" href="model_doc/prophetnet.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/prophetnet.html#prophetnetconfig">ProphetNetConfig</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/prophetnet.html#prophetnettokenizer">ProphetNetTokenizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/prophetnet.html#prophetnet-specific-outputs">ProphetNet specific outputs</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/prophetnet.html#prophetnetmodel">ProphetNetModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/prophetnet.html#prophetnetencoder">ProphetNetEncoder</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/prophetnet.html#prophetnetdecoder">ProphetNetDecoder</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/prophetnet.html#prophetnetforconditionalgeneration">ProphetNetForConditionalGeneration</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/prophetnet.html#prophetnetforcausallm">ProphetNetForCausalLM</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/rag.html">RAG</a><ul>
<li class="toctree-l2"><a class="reference internal" href="model_doc/rag.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/rag.html#ragconfig">RagConfig</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/rag.html#ragtokenizer">RagTokenizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/rag.html#rag-specific-outputs">Rag specific outputs</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/rag.html#ragretriever">RagRetriever</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/rag.html#ragmodel">RagModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/rag.html#ragsequenceforgeneration">RagSequenceForGeneration</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/rag.html#ragtokenforgeneration">RagTokenForGeneration</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/rag.html#tfragmodel">TFRagModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/rag.html#tfragsequenceforgeneration">TFRagSequenceForGeneration</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/rag.html#tfragtokenforgeneration">TFRagTokenForGeneration</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/reformer.html">Reformer</a><ul>
<li class="toctree-l2"><a class="reference internal" href="model_doc/reformer.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/reformer.html#axial-positional-encodings">Axial Positional Encodings</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/reformer.html#lsh-self-attention">LSH Self Attention</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/reformer.html#local-self-attention">Local Self Attention</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/reformer.html#training">Training</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/reformer.html#reformerconfig">ReformerConfig</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/reformer.html#reformertokenizer">ReformerTokenizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/reformer.html#reformertokenizerfast">ReformerTokenizerFast</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/reformer.html#reformermodel">ReformerModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/reformer.html#reformermodelwithlmhead">ReformerModelWithLMHead</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/reformer.html#reformerformaskedlm">ReformerForMaskedLM</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/reformer.html#reformerforsequenceclassification">ReformerForSequenceClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/reformer.html#reformerforquestionanswering">ReformerForQuestionAnswering</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/retribert.html">RetriBERT</a><ul>
<li class="toctree-l2"><a class="reference internal" href="model_doc/retribert.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/retribert.html#retribertconfig">RetriBertConfig</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/retribert.html#retriberttokenizer">RetriBertTokenizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/retribert.html#retriberttokenizerfast">RetriBertTokenizerFast</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/retribert.html#retribertmodel">RetriBertModel</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/roberta.html">RoBERTa</a><ul>
<li class="toctree-l2"><a class="reference internal" href="model_doc/roberta.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/roberta.html#robertaconfig">RobertaConfig</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/roberta.html#robertatokenizer">RobertaTokenizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/roberta.html#robertatokenizerfast">RobertaTokenizerFast</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/roberta.html#robertamodel">RobertaModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/roberta.html#robertaforcausallm">RobertaForCausalLM</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/roberta.html#robertaformaskedlm">RobertaForMaskedLM</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/roberta.html#robertaforsequenceclassification">RobertaForSequenceClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/roberta.html#robertaformultiplechoice">RobertaForMultipleChoice</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/roberta.html#robertafortokenclassification">RobertaForTokenClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/roberta.html#robertaforquestionanswering">RobertaForQuestionAnswering</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/roberta.html#tfrobertamodel">TFRobertaModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/roberta.html#tfrobertaformaskedlm">TFRobertaForMaskedLM</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/roberta.html#tfrobertaforsequenceclassification">TFRobertaForSequenceClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/roberta.html#tfrobertaformultiplechoice">TFRobertaForMultipleChoice</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/roberta.html#tfrobertafortokenclassification">TFRobertaForTokenClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/roberta.html#tfrobertaforquestionanswering">TFRobertaForQuestionAnswering</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/roberta.html#flaxrobertamodel">FlaxRobertaModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/roberta.html#flaxrobertaformaskedlm">FlaxRobertaForMaskedLM</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/roberta.html#flaxrobertaforsequenceclassification">FlaxRobertaForSequenceClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/roberta.html#flaxrobertaformultiplechoice">FlaxRobertaForMultipleChoice</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/roberta.html#flaxrobertafortokenclassification">FlaxRobertaForTokenClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/roberta.html#flaxrobertaforquestionanswering">FlaxRobertaForQuestionAnswering</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/speech_to_text.html">Speech2Text</a><ul>
<li class="toctree-l2"><a class="reference internal" href="model_doc/speech_to_text.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/speech_to_text.html#inference">Inference</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/speech_to_text.html#speech2textconfig">Speech2TextConfig</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/speech_to_text.html#speech2texttokenizer">Speech2TextTokenizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/speech_to_text.html#speech2textfeatureextractor">Speech2TextFeatureExtractor</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/speech_to_text.html#speech2textprocessor">Speech2TextProcessor</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/speech_to_text.html#speech2textmodel">Speech2TextModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/speech_to_text.html#speech2textforconditionalgeneration">Speech2TextForConditionalGeneration</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/squeezebert.html">SqueezeBERT</a><ul>
<li class="toctree-l2"><a class="reference internal" href="model_doc/squeezebert.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/squeezebert.html#squeezebertconfig">SqueezeBertConfig</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/squeezebert.html#squeezeberttokenizer">SqueezeBertTokenizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/squeezebert.html#squeezeberttokenizerfast">SqueezeBertTokenizerFast</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/squeezebert.html#squeezebertmodel">SqueezeBertModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/squeezebert.html#squeezebertformaskedlm">SqueezeBertForMaskedLM</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/squeezebert.html#squeezebertforsequenceclassification">SqueezeBertForSequenceClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/squeezebert.html#squeezebertformultiplechoice">SqueezeBertForMultipleChoice</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/squeezebert.html#squeezebertfortokenclassification">SqueezeBertForTokenClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/squeezebert.html#squeezebertforquestionanswering">SqueezeBertForQuestionAnswering</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/t5.html">T5</a><ul>
<li class="toctree-l2"><a class="reference internal" href="model_doc/t5.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/t5.html#training">Training</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/t5.html#t5config">T5Config</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/t5.html#t5tokenizer">T5Tokenizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/t5.html#t5tokenizerfast">T5TokenizerFast</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/t5.html#t5model">T5Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/t5.html#t5forconditionalgeneration">T5ForConditionalGeneration</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/t5.html#t5encodermodel">T5EncoderModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/t5.html#tft5model">TFT5Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/t5.html#tft5forconditionalgeneration">TFT5ForConditionalGeneration</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/t5.html#tft5encodermodel">TFT5EncoderModel</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/tapas.html">TAPAS</a><ul>
<li class="toctree-l2"><a class="reference internal" href="model_doc/tapas.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/tapas.html#usage-fine-tuning">Usage: fine-tuning</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/tapas.html#usage-inference">Usage: inference</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/tapas.html#tapas-specific-outputs">Tapas specific outputs</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/tapas.html#tapasconfig">TapasConfig</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/tapas.html#tapastokenizer">TapasTokenizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/tapas.html#tapasmodel">TapasModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/tapas.html#tapasformaskedlm">TapasForMaskedLM</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/tapas.html#tapasforsequenceclassification">TapasForSequenceClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/tapas.html#tapasforquestionanswering">TapasForQuestionAnswering</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/transformerxl.html">Transformer XL</a><ul>
<li class="toctree-l2"><a class="reference internal" href="model_doc/transformerxl.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/transformerxl.html#transfoxlconfig">TransfoXLConfig</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/transformerxl.html#transfoxltokenizer">TransfoXLTokenizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/transformerxl.html#transfoxl-specific-outputs">TransfoXL specific outputs</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/transformerxl.html#transfoxlmodel">TransfoXLModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/transformerxl.html#transfoxllmheadmodel">TransfoXLLMHeadModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/transformerxl.html#transfoxlforsequenceclassification">TransfoXLForSequenceClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/transformerxl.html#tftransfoxlmodel">TFTransfoXLModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/transformerxl.html#tftransfoxllmheadmodel">TFTransfoXLLMHeadModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/transformerxl.html#tftransfoxlforsequenceclassification">TFTransfoXLForSequenceClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/transformerxl.html#internal-layers">Internal Layers</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/vit.html">Vision Transformer (ViT)</a><ul>
<li class="toctree-l2"><a class="reference internal" href="model_doc/vit.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/vit.html#vitconfig">ViTConfig</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/vit.html#vitfeatureextractor">ViTFeatureExtractor</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/vit.html#vitmodel">ViTModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/vit.html#vitforimageclassification">ViTForImageClassification</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/wav2vec2.html">Wav2Vec2</a><ul>
<li class="toctree-l2"><a class="reference internal" href="model_doc/wav2vec2.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/wav2vec2.html#wav2vec2config">Wav2Vec2Config</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/wav2vec2.html#wav2vec2ctctokenizer">Wav2Vec2CTCTokenizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/wav2vec2.html#wav2vec2featureextractor">Wav2Vec2FeatureExtractor</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/wav2vec2.html#wav2vec2processor">Wav2Vec2Processor</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/wav2vec2.html#wav2vec2model">Wav2Vec2Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/wav2vec2.html#wav2vec2forctc">Wav2Vec2ForCTC</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/xlm.html">XLM</a><ul>
<li class="toctree-l2"><a class="reference internal" href="model_doc/xlm.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/xlm.html#xlmconfig">XLMConfig</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/xlm.html#xlmtokenizer">XLMTokenizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/xlm.html#xlm-specific-outputs">XLM specific outputs</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/xlm.html#xlmmodel">XLMModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/xlm.html#xlmwithlmheadmodel">XLMWithLMHeadModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/xlm.html#xlmforsequenceclassification">XLMForSequenceClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/xlm.html#xlmformultiplechoice">XLMForMultipleChoice</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/xlm.html#xlmfortokenclassification">XLMForTokenClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/xlm.html#xlmforquestionansweringsimple">XLMForQuestionAnsweringSimple</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/xlm.html#xlmforquestionanswering">XLMForQuestionAnswering</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/xlm.html#tfxlmmodel">TFXLMModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/xlm.html#tfxlmwithlmheadmodel">TFXLMWithLMHeadModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/xlm.html#tfxlmforsequenceclassification">TFXLMForSequenceClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/xlm.html#tfxlmformultiplechoice">TFXLMForMultipleChoice</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/xlm.html#tfxlmfortokenclassification">TFXLMForTokenClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/xlm.html#tfxlmforquestionansweringsimple">TFXLMForQuestionAnsweringSimple</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/xlmprophetnet.html">XLM-ProphetNet</a><ul>
<li class="toctree-l2"><a class="reference internal" href="model_doc/xlmprophetnet.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/xlmprophetnet.html#xlmprophetnetconfig">XLMProphetNetConfig</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/xlmprophetnet.html#xlmprophetnettokenizer">XLMProphetNetTokenizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/xlmprophetnet.html#xlmprophetnetmodel">XLMProphetNetModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/xlmprophetnet.html#xlmprophetnetencoder">XLMProphetNetEncoder</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/xlmprophetnet.html#xlmprophetnetdecoder">XLMProphetNetDecoder</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/xlmprophetnet.html#xlmprophetnetforconditionalgeneration">XLMProphetNetForConditionalGeneration</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/xlmprophetnet.html#xlmprophetnetforcausallm">XLMProphetNetForCausalLM</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/xlmroberta.html">XLM-RoBERTa</a><ul>
<li class="toctree-l2"><a class="reference internal" href="model_doc/xlmroberta.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/xlmroberta.html#xlmrobertaconfig">XLMRobertaConfig</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/xlmroberta.html#xlmrobertatokenizer">XLMRobertaTokenizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/xlmroberta.html#xlmrobertatokenizerfast">XLMRobertaTokenizerFast</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/xlmroberta.html#xlmrobertamodel">XLMRobertaModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/xlmroberta.html#xlmrobertaforcausallm">XLMRobertaForCausalLM</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/xlmroberta.html#xlmrobertaformaskedlm">XLMRobertaForMaskedLM</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/xlmroberta.html#xlmrobertaforsequenceclassification">XLMRobertaForSequenceClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/xlmroberta.html#xlmrobertaformultiplechoice">XLMRobertaForMultipleChoice</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/xlmroberta.html#xlmrobertafortokenclassification">XLMRobertaForTokenClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/xlmroberta.html#xlmrobertaforquestionanswering">XLMRobertaForQuestionAnswering</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/xlmroberta.html#tfxlmrobertamodel">TFXLMRobertaModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/xlmroberta.html#tfxlmrobertaformaskedlm">TFXLMRobertaForMaskedLM</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/xlmroberta.html#tfxlmrobertaforsequenceclassification">TFXLMRobertaForSequenceClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/xlmroberta.html#tfxlmrobertaformultiplechoice">TFXLMRobertaForMultipleChoice</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/xlmroberta.html#tfxlmrobertafortokenclassification">TFXLMRobertaForTokenClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/xlmroberta.html#tfxlmrobertaforquestionanswering">TFXLMRobertaForQuestionAnswering</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/xlnet.html">XLNet</a><ul>
<li class="toctree-l2"><a class="reference internal" href="model_doc/xlnet.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/xlnet.html#xlnetconfig">XLNetConfig</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/xlnet.html#xlnettokenizer">XLNetTokenizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/xlnet.html#xlnettokenizerfast">XLNetTokenizerFast</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/xlnet.html#xlnet-specific-outputs">XLNet specific outputs</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/xlnet.html#xlnetmodel">XLNetModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/xlnet.html#xlnetlmheadmodel">XLNetLMHeadModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/xlnet.html#xlnetforsequenceclassification">XLNetForSequenceClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/xlnet.html#xlnetformultiplechoice">XLNetForMultipleChoice</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/xlnet.html#xlnetfortokenclassification">XLNetForTokenClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/xlnet.html#xlnetforquestionansweringsimple">XLNetForQuestionAnsweringSimple</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/xlnet.html#xlnetforquestionanswering">XLNetForQuestionAnswering</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/xlnet.html#tfxlnetmodel">TFXLNetModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/xlnet.html#tfxlnetlmheadmodel">TFXLNetLMHeadModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/xlnet.html#tfxlnetforsequenceclassification">TFXLNetForSequenceClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/xlnet.html#tflnetformultiplechoice">TFLNetForMultipleChoice</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/xlnet.html#tfxlnetfortokenclassification">TFXLNetForTokenClassification</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/xlnet.html#tfxlnetforquestionansweringsimple">TFXLNetForQuestionAnsweringSimple</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/xlsr_wav2vec2.html">XLSR-Wav2Vec2</a><ul>
<li class="toctree-l2"><a class="reference internal" href="model_doc/xlsr_wav2vec2.html#overview">Overview</a></li>
</ul>
</li>
</ul>
</div>
<div class="toctree-wrapper compound">
<p class="caption"><span class="caption-text">Internal Helpers</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="internal/modeling_utils.html">Custom Layers and Utilities</a><ul>
<li class="toctree-l2"><a class="reference internal" href="internal/modeling_utils.html#pytorch-custom-modules">Pytorch custom modules</a></li>
<li class="toctree-l2"><a class="reference internal" href="internal/modeling_utils.html#pytorch-helper-functions">PyTorch Helper Functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="internal/modeling_utils.html#tensorflow-custom-layers">TensorFlow custom layers</a></li>
<li class="toctree-l2"><a class="reference internal" href="internal/modeling_utils.html#tensorflow-loss-functions">TensorFlow loss functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="internal/modeling_utils.html#tensorflow-helper-functions">TensorFlow Helper Functions</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="internal/pipelines_utils.html">Utilities for pipelines</a><ul>
<li class="toctree-l2"><a class="reference internal" href="internal/pipelines_utils.html#argument-handling">Argument handling</a></li>
<li class="toctree-l2"><a class="reference internal" href="internal/pipelines_utils.html#data-format">Data format</a></li>
<li class="toctree-l2"><a class="reference internal" href="internal/pipelines_utils.html#utilities">Utilities</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="internal/tokenization_utils.html">Utilities for Tokenizers</a><ul>
<li class="toctree-l2"><a class="reference internal" href="internal/tokenization_utils.html#pretrainedtokenizerbase">PreTrainedTokenizerBase</a></li>
<li class="toctree-l2"><a class="reference internal" href="internal/tokenization_utils.html#specialtokensmixin">SpecialTokensMixin</a></li>
<li class="toctree-l2"><a class="reference internal" href="internal/tokenization_utils.html#enums-and-namedtuples">Enums and namedtuples</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="internal/trainer_utils.html">Utilities for Trainer</a><ul>
<li class="toctree-l2"><a class="reference internal" href="internal/trainer_utils.html#utilities">Utilities</a></li>
<li class="toctree-l2"><a class="reference internal" href="internal/trainer_utils.html#callbacks-internals">Callbacks internals</a></li>
<li class="toctree-l2"><a class="reference internal" href="internal/trainer_utils.html#distributed-evaluation">Distributed Evaluation</a></li>
<li class="toctree-l2"><a class="reference internal" href="internal/trainer_utils.html#id1">Distributed Evaluation</a></li>
<li class="toctree-l2"><a class="reference internal" href="internal/trainer_utils.html#debug-utilities">Debug Utilities</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="internal/generation_utils.html">Utilities for Generation</a><ul>
<li class="toctree-l2"><a class="reference internal" href="internal/generation_utils.html#generate-outputs">Generate Outputs</a></li>
<li class="toctree-l2"><a class="reference internal" href="internal/generation_utils.html#logitsprocessor">LogitsProcessor</a></li>
<li class="toctree-l2"><a class="reference internal" href="internal/generation_utils.html#stoppingcriteria">StoppingCriteria</a></li>
<li class="toctree-l2"><a class="reference internal" href="internal/generation_utils.html#beamsearch">BeamSearch</a></li>
<li class="toctree-l2"><a class="reference internal" href="internal/generation_utils.html#utilities">Utilities</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="internal/file_utils.html">General Utilities</a><ul>
<li class="toctree-l2"><a class="reference internal" href="internal/file_utils.html#enums-and-namedtuples">Enums and namedtuples</a></li>
<li class="toctree-l2"><a class="reference internal" href="internal/file_utils.html#special-decorators">Special Decorators</a></li>
<li class="toctree-l2"><a class="reference internal" href="internal/file_utils.html#special-properties">Special Properties</a></li>
<li class="toctree-l2"><a class="reference internal" href="internal/file_utils.html#other-utilities">Other Utilities</a></li>
</ul>
</li>
</ul>
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="quicktour.html" class="btn btn-neutral float-right" title="Quick tour" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2020, The Hugging Face Team, Licenced under the Apache License, Version 2.0

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
    <!-- Theme Analytics -->
    <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-83738774-2', 'auto');
    ga('send', 'pageview');
    </script>

    
   

</body>
</html>